import streamlit as st
import os
import json
import datetime
import time
import requests
import base64
from pydub import AudioSegment
import shutil
import traceback
from io import BytesIO
import tempfile
import threading
import re
import streamlit_js_eval

# ×”×’×“×¨×ª ×”×›×•×ª×¨×ª ×•×¡×’× ×•×Ÿ ×”××¤×œ×™×§×¦×™×”
st.set_page_config(
    page_title="××¢×¨×›×ª ×ª××œ×•×œ ×©×™×¢×•×¨×™ ×ª×•×¨×”",
    page_icon="ğŸ™ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ×›×•×ª×¨×ª ×¨××©×™×ª
st.title("××¢×¨×›×ª ×ª××œ×•×œ ×©×™×¢×•×¨×™ ×ª×•×¨×”")
st.markdown("### ×”××¢×¨×›×ª ×××¤×©×¨×ª ×ª××œ×•×œ ××•×˜×•××˜×™ ×©×œ ×©×™×¢×•×¨×™× ×¢× Google Gemini")

# ×¡×™×“×•×¨ ×›×™×•×•×Ÿ ×”×˜×§×¡×˜ ×œ×¢×‘×¨×™×ª
st.markdown("""
<style>
    body {
        direction: rtl;
        text-align: right;
    }
    .stTextInput, .stTextArea {
        direction: rtl;
        text-align: right;
    }
    .streamlit-expanderHeader {
        direction: rtl;
        text-align: right;
    }
    p, h1, h2, h3, h4, h5, h6, div {
        direction: rtl;
        text-align: right;
    }
    .stButton button {
        float: right;
    }
    /* ×”×¡×ª×¨×ª ×›×¤×ª×•×¨ ×”×¤×ª×™×—×” ×”××§×•×¨×™ ×©×œ ×”×¡×¨×’×œ */
    [data-testid="collapsedControl"] {
        display: none !important;
    }
    
    /* ×™×¦×™×¨×ª ×›×¤×ª×•×¨ ×—×“×© ×‘×¦×“ ×™××™×Ÿ */
    .sidebar-toggle {
        position: fixed;
        top: 50%;
        right: 0;
        transform: translateY(-50%);
        background-color: #4e8cff;
        color: white;
        border: none;
        border-radius: 4px 0 0 4px;
        padding: 10px 5px;
        cursor: pointer;
        z-index: 1000;
        box-shadow: -2px 0 5px rgba(0,0,0,0.2);
    }
    
    /* ×¢×™×¦×•×‘ ×”×—×¥ */
    .sidebar-toggle-icon {
        display: inline-block;
        width: 0;
        height: 0;
        border-top: 6px solid transparent;
        border-bottom: 6px solid transparent;
        border-right: 6px solid white;
    }
    
    /* ×”×™×¤×•×š ×”×—×¥ ×›××©×¨ ×”×¡×¨×’×œ ×¤×ª×•×— */
    .sidebar-open .sidebar-toggle-icon {
        border-right: none;
        border-left: 6px solid white;
    }
    
    /* ×”×ª×××ª ×©×•×œ×™ ×”×ª×•×›×Ÿ ×”×¨××©×™ */
    .main-content {
        transition: margin-right 0.3s;
    }
    
    /* ×”×ª×××ª ×©×•×œ×™ ×”×ª×•×›×Ÿ ×›××©×¨ ×”×¡×¨×’×œ ×¤×ª×•×— */
    .sidebar-open .main-content {
        margin-right: 260px;
    }
</style>
            
<script>
document.addEventListener('DOMContentLoaded', function() {
    // ×™×¦×™×¨×ª ×›×¤×ª×•×¨ ×—×“×©
    const sidebarToggle = document.createElement('button');
    sidebarToggle.className = 'sidebar-toggle';
    sidebarToggle.innerHTML = '<span class="sidebar-toggle-icon"></span>';
    document.body.appendChild(sidebarToggle);
    
    // ×”×•×¡×¤×ª ×”××–× ×” ×œ×œ×—×™×¦×”
    sidebarToggle.addEventListener('click', function() {
        // ××¦×™××ª ×›×¤×ª×•×¨ ×”×¡×¨×’×œ ×”××§×•×¨×™ ×•×œ×—×™×¦×” ×¢×œ×™×• ×‘××•×¤×Ÿ ×ª×›× ×•×ª×™
        const originalToggle = document.querySelector('[data-testid="collapsedControl"]');
        if (originalToggle) {
            originalToggle.click();
        }
        
        // ×¢×“×›×•×Ÿ ×¡×˜×™×™×œ ×”×—×¥
        document.body.classList.toggle('sidebar-open');
    });
    
    // ×‘×“×™×§×” ×× ×”×¡×¨×’×œ ×¤×ª×•×— ×‘×˜×¢×™× ×”
    const sidebarExpanded = document.querySelector('.stSidebar').style.width !== '0px';
    if (sidebarExpanded) {
        document.body.classList.add('sidebar-open');
    }
});
</script>
""", unsafe_allow_html=True)

class TokenUsageManager:
    """×× ×”×œ ×©×™××•×© ×‘×˜×•×§× ×™× ×‘×¤×¨×•×™×§×˜×™× ×©×•× ×™× ×©×œ Google AI Studio."""
    
    def __init__(self, usage_file="token_usage.json"):
        self.usage_file = usage_file
        self.usage_data = self._load_usage_data()
        
    def _load_usage_data(self):
        """×˜×¢×™× ×ª × ×ª×•× ×™ ×©×™××•×© ×‘×˜×•×§× ×™× ××§×•×‘×¥, ××• ×™×¦×™×¨×ª ×§×•×‘×¥ ×—×“×© ×× ×œ× ×§×™×™×."""
        if os.path.exists(self.usage_file):
            try:
                with open(self.usage_file, "r") as f:
                    return json.load(f)
            except Exception as e:
                st.warning(f"××–×”×¨×”: × ×›×©×œ ×‘×˜×¢×™× ×ª × ×ª×•× ×™ ×©×™××•×© ×‘×˜×•×§× ×™×: {e}")
        
        # ××‘× ×” ×‘×¨×™×¨×ª ××—×“×œ ×× ×”×§×•×‘×¥ ×œ× ×§×™×™× ××• ×œ× ×ª×§×™×Ÿ
        return {
            "projects": {},
            "last_updated": datetime.datetime.now().strftime("%Y-%m-%d")
        }
    
    def _save_usage_data(self):
        """×©××™×¨×ª × ×ª×•× ×™ ×©×™××•×© ×‘×˜×•×§× ×™× ×œ×§×•×‘×¥."""
        try:
            with open(self.usage_file, "w") as f:
                json.dump(self.usage_data, f, indent=2)
        except Exception as e:
            st.warning(f"××–×”×¨×”: × ×›×©×œ ×‘×©××™×¨×ª × ×ª×•× ×™ ×©×™××•×© ×‘×˜×•×§× ×™×: {e}")
    
    def reset_daily_counters_if_needed(self):
        """××™×¤×•×¡ ××•× ×” ×™×•××™ ×× ×”×ª××¨×™×š ×”×ª×—×œ×£."""
        today = datetime.datetime.now().strftime("%Y-%m-%d")
        last_updated = self.usage_data.get("last_updated", "")
        
        if today != last_updated:
            st.info(f"×–×•×”×” ×™×•× ×—×“×©. ×××¤×¡ ××ª ××•× ×™ ×”×©×™××•×© ×”×™×•××™ ×‘×˜×•×§× ×™×.")
            # ××™×¤×•×¡ ×©×™××•×© ×™×•××™ ×œ×›×œ ×”×¤×¨×•×™×§×˜×™×
            for project_id in self.usage_data["projects"]:
                if "daily_usage" in self.usage_data["projects"][project_id]:
                    self.usage_data["projects"][project_id]["daily_usage"] = 0
            
            self.usage_data["last_updated"] = today
            self._save_usage_data()
    
    def register_project(self, project_id, daily_limit=1000000):
        """×¨×™×©×•× ×¤×¨×•×™×§×˜ ×—×“×© ××• ×¢×“×›×•×Ÿ ×”××’×‘×œ×•×ª ×©×œ×•."""
        if project_id not in self.usage_data["projects"]:
            self.usage_data["projects"][project_id] = {
                "daily_limit": daily_limit,
                "daily_usage": 0,
                "total_usage": 0
            }
        else:
            # ×¢×“×›×•×Ÿ ××’×‘×œ×” ×™×•××™×ª ×× ×”×©×ª× ×ª×”
            self.usage_data["projects"][project_id]["daily_limit"] = daily_limit
        
        self._save_usage_data()
    
    def record_usage(self, project_id, tokens_used):
        """×¨×™×©×•× ×©×™××•×© ×‘×˜×•×§× ×™× ×œ×¤×¨×•×™×§×˜."""
        if project_id not in self.usage_data["projects"]:
            self.register_project(project_id)
        
        self.usage_data["projects"][project_id]["daily_usage"] += tokens_used
        self.usage_data["projects"][project_id]["total_usage"] += tokens_used
        
        self._save_usage_data()
    
    def get_available_project(self, project_ids):
        """××¦×™××ª ×¤×¨×•×™×§×˜ ×¢× ×˜×•×§× ×™× ×–××™× ×™× ××¨×©×™××” × ×ª×•× ×”."""
        self.reset_daily_counters_if_needed()
        
        for project_id in project_ids:
            if project_id not in self.usage_data["projects"]:
                # ×¤×¨×•×™×§×˜ ×—×“×©, ×¨×™×©×•× ××•×˜×•××˜×™
                self.register_project(project_id)
                return project_id
            
            project_data = self.usage_data["projects"][project_id]
            if project_data["daily_usage"] < project_data["daily_limit"]:
                return project_id
        
        return None
    
    def get_usage_summary(self):
        """×”×¦×’×ª ×¡×™×›×•× ×©×™××•×© ×‘×˜×•×§× ×™× ×‘×›×œ ×”×¤×¨×•×™×§×˜×™×."""
        self.reset_daily_counters_if_needed()
        
        summary = []
        for project_id, data in self.usage_data["projects"].items():
            remaining = data["daily_limit"] - data["daily_usage"]
            percent_used = (data["daily_usage"] / data["daily_limit"]) * 100 if data["daily_limit"] > 0 else 0
            
            summary.append({
                "project_id": project_id,
                "daily_limit": data["daily_limit"],
                "daily_usage": data["daily_usage"],
                "remaining": remaining,
                "percent_used": percent_used,
                "total_usage": data["total_usage"]
            })
        
        return summary


def transcribe_with_gemini(api_key, model, prompt, audio_bytes, progress_bar=None):
    """×ª××œ×•×œ ××•×“×™×• ×‘×××¦×¢×•×ª ×”-API ×©×œ Gemini"""
    
    # × ×§×•×“×ª ×§×¦×” ×©×œ ×”-API
    url = f"https://generativelanguage.googleapis.com/v1beta/models/{model}:generateContent?key={api_key}"
    
    # ×”×›× ×ª ×‘×§×©×” ××¨×•×‘×ª ×—×œ×§×™× - ×–×”×• ×”××‘× ×” ×”× ×“×¨×© ×œ×©×œ×™×—×ª ×§×‘×¦×™× ×œ-Gemini
    audio_b64 = base64.b64encode(audio_bytes).decode('utf-8')
    
    payload = {
        "contents": [
            {
                "parts": [
                    {"text": prompt},
                    {
                        "inline_data": {
                            "mime_type": "audio/mp3",
                            "data": audio_b64
                        }
                    }
                ]
            }
        ],
        "generationConfig": {
            "temperature": 0.1,  # ×˜××¤×¨×˜×•×¨×” × ××•×›×” ×œ×ª××œ×•×œ ××“×•×™×§ ×™×•×ª×¨
            "maxOutputTokens": 8192
        }
    }
    
    # ×‘×™×¦×•×¢ ×‘×§×©×” ×¢× ×œ×•×’×™×§×ª × ×™×¡×™×•×Ÿ ×—×•×–×¨
    max_retries = 3
    for retry in range(max_retries):
        try:
            response = requests.post(url, json=payload)
            
            if response.status_code == 200:
                break
            else:
                if progress_bar:
                    progress_bar.text(f"×©×’×™××ª API (× ×™×¡×™×•×Ÿ {retry+1}/{max_retries}): {response.status_code}")
                if retry < max_retries - 1:
                    time.sleep(2 * (retry + 1))  # ×”××ª× ×” ×’×“×œ×” ××§×¡×¤×•× × ×¦×™××œ×™×ª
        except Exception as e:
            if progress_bar:
                progress_bar.text(f"×©×’×™××ª ×‘×§×©×” (× ×™×¡×™×•×Ÿ {retry+1}/{max_retries}): {e}")
            if retry < max_retries - 1:
                time.sleep(2 * (retry + 1))
    
    if response.status_code != 200:
        raise Exception(f"×‘×§×©×ª Gemini × ×›×©×œ×” ×¢× ×§×•×“ {response.status_code}: {response.text}")
    
    # ×¤×¢× ×•×— ×”×ª×©×•×‘×”
    response_data = response.json()
    
    # ×—×™×œ×•×¥ ×”×ª××œ×•×œ ××”×ª×©×•×‘×”
    try:
        transcript = response_data["candidates"][0]["content"]["parts"][0]["text"]
        return transcript.strip()
    except (KeyError, IndexError) as e:
        if progress_bar:
            progress_bar.text(f"×©×’×™××” ×‘×¤×¢× ×•×— ×ª×©×•×‘×ª Gemini: {e}")
            progress_bar.text(f"××‘× ×” ×”×ª×©×•×‘×”: {json.dumps(response_data, indent=2)}")
        return ""


def process_audio(uploaded_file, api_key, projects, model, segment_length, overlap, custom_prompt, progress_bar, status_text):
    """×¢×™×‘×•×“ ×§×•×‘×¥ ××•×“×™×•: ×˜×¢×™× ×”, ×—×œ×•×§×”, ×ª××œ×•×œ ×•×©×™×œ×•×‘"""
    
    # ×™×¦×™×¨×ª ×× ×”×œ ×©×™××•×© ×‘×˜×•×§× ×™×
    token_manager = TokenUsageManager()
    
    # ×¨×™×©×•× ×›×œ ×”×¤×¨×•×™×§×˜×™×
    project_ids = [p.strip() for p in projects.split(",") if p.strip()]
    if not project_ids:
        status_text.error("×©×’×™××”: ×™×© ×œ×¡×¤×§ ×œ×¤×—×•×ª ××–×”×” ×¤×¨×•×™×§×˜ ××—×“ ×©×œ Google Cloud")
        return None
    
    for project_id in project_ids:
        token_manager.register_project(project_id)
    
    # ×”×¦×’×ª ×©×™××•×© ×‘×˜×•×§× ×™× ×œ×¤× ×™ ×”×ª×—×œ×”
    status_text.info("×©×™××•×© × ×•×›×—×™ ×‘×˜×•×§× ×™× ×‘×¤×¨×•×™×§×˜×™×:")
    for project in token_manager.get_usage_summary():
        status_text.info(f"  {project['project_id']}: {project['daily_usage']}/{project['daily_limit']} ×˜×•×§× ×™× ×‘×©×™××•×© ({project['percent_used']:.1f}%)")
    
    # ×™×¦×™×¨×ª ×¡×¤×¨×™×” ×–×× ×™×ª
    with tempfile.TemporaryDirectory() as temp_dir:
        status_text.info(f"× ×•×¦×¨×” ×¡×¤×¨×™×” ×–×× ×™×ª: {temp_dir}")
        
        try:
            # ×©××™×¨×ª ×”×§×•×‘×¥ ×”××•×¢×œ×” ×œ×“×™×¡×§
            mp3_path = os.path.join(temp_dir, "uploaded_audio.mp3")
            with open(mp3_path, "wb") as f:
                f.write(uploaded_file.getbuffer())
            
            status_text.info(f"××¢×‘×“ ×§×•×‘×¥ ××•×“×™×•: {uploaded_file.name}")
            
            # ×˜×¢×™× ×ª ×§×•×‘×¥ ×”××•×“×™×•
            try:
                status_text.info("×˜×•×¢×Ÿ ×§×•×‘×¥ ××•×“×™×•...")
                audio = AudioSegment.from_mp3(mp3_path)
                status_text.info(f"×§×•×‘×¥ ××•×“×™×• × ×˜×¢×Ÿ: {len(audio) / 1000 / 60:.2f} ×“×§×•×ª")
            except Exception as e:
                status_text.error(f"× ×›×©×œ ×‘×˜×¢×™× ×ª ×§×•×‘×¥ ×”××•×“×™×•: {e}. ×•×“× ×©×”×ª×§× ×ª ffmpeg ×•×©×”×•× × ××¦× ×‘-PATH ×©×œ×š.")
                return None
            
            # ×—×™×©×•×‘ ×’×•×“×œ ××§×˜×¢ ×•×—×¤×™×¤×” ×‘××™×œ×™×©× ×™×•×ª
            segment_length_ms = segment_length * 60 * 1000
            overlap_ms = overlap * 1000
            
            if segment_length_ms <= overlap_ms:
                status_text.error(f"××•×¨×š ×”××§×˜×¢ ({segment_length} ×“×§×•×ª) ×—×™×™×‘ ×œ×”×™×•×ª ×’×“×•×œ ××”×—×¤×™×¤×” ({overlap} ×©× ×™×•×ª)")
                return None
            
            # ×—×™×©×•×‘ ××¡×¤×¨ ×”××§×˜×¢×™×
            total_duration_ms = len(audio)
            effective_length_ms = segment_length_ms - overlap_ms
            num_segments = (total_duration_ms - overlap_ms + effective_length_ms - 1) // effective_length_ms
            
            status_text.info(f"×”××•×“×™×• ×™×—×•×œ×§ ×œ-{num_segments} ××§×˜×¢×™×:")
            status_text.info(f"- ×›×œ ××§×˜×¢: ××§×¡×™××•× {segment_length} ×“×§×•×ª")
            status_text.info(f"- ×—×¤×™×¤×” ×‘×™×Ÿ ××§×˜×¢×™×: {overlap} ×©× ×™×•×ª")
            
            # ×”×’×“×¨×ª ××“ ×”×ª×§×“××•×ª
            progress_bar.progress(0, text="××ª×—×™×œ ×¢×™×‘×•×“...")
            
            # ×™×¦×™×¨×ª ××§×˜×¢×™×
            segments = []
            for i in range(num_segments):
                start_ms = i * effective_length_ms
                end_ms = min(total_duration_ms, start_ms + segment_length_ms)
                
                # ×™×¦×•× ××§×˜×¢ ×œ×§×•×‘×¥ ×–×× ×™
                temp_file = os.path.join(temp_dir, f"segment_{i:03d}.mp3")
                status_text.info(f"×™×•×¦×¨ ××§×˜×¢ {i+1}/{num_segments}: {start_ms/1000/60:.2f}-{end_ms/1000/60:.2f} ×“×§×•×ª")
                
                # ×—×™×œ×•×¥ ××§×˜×¢ ×•×™×¦×•×
                segment = audio[start_ms:end_ms]
                segment.export(temp_file, format="mp3")
                segments.append(temp_file)
                
                # ×¢×“×›×•×Ÿ ××“ ×”×ª×§×“××•×ª - ×©×œ×‘ ×”×—×œ×•×§×” ×œ××§×˜×¢×™×
                segment_progress = (i + 1) / (num_segments * 3)  # ×©×œ×™×© ×¨××©×•×Ÿ ×©×œ ×”×ª×”×œ×™×š
                progress_bar.progress(segment_progress, text=f"×—×•×œ×§ ××§×˜×¢ {i+1}/{num_segments}...")
            
            # ×¢×™×‘×•×“ ×›×œ ××§×˜×¢
            processed_transcriptions = process_segments(
                api_key, model, token_manager, project_ids, 
                segments, temp_dir, custom_prompt, 
                progress_bar, status_text, num_segments
            )
            
            if not processed_transcriptions:
                status_text.error("×œ× ×”×¦×œ×—× ×• ×œ×§×‘×œ ×ª××œ×•×œ ×œ××£ ××§×˜×¢")
                return None
            
            # ×©×™×œ×•×‘ ×›×œ ×”×ª××œ×•×œ×™× ×”××¢×•×‘×“×™×
            combined_text = combine_transcriptions(processed_transcriptions, progress_bar, status_text)
            
            # ×”×¦×’ ×©×™××•×© ×‘×˜×•×§× ×™× ××¢×•×“×›×Ÿ
            status_text.info("\n×©×™××•×© ×‘×˜×•×§× ×™× ××¢×•×“×›×Ÿ ×œ××—×¨ ×¢×™×‘×•×“:")
            for project in token_manager.get_usage_summary():
                status_text.info(f"  {project['project_id']}: {project['daily_usage']}/{project['daily_limit']} ×˜×•×§× ×™× ×‘×©×™××•×© ({project['percent_used']:.1f}%)")
            
            progress_bar.progress(1.0, text="×”×•×©×œ× ×‘×”×¦×œ×—×”!")
            status_text.success("×ª××œ×•×œ ×”×§×•×‘×¥ ×”×•×©×œ× ×‘×”×¦×œ×—×”")
            
            return combined_text
            
        except Exception as e:
            status_text.error(f"×©×’×™××”: {str(e)}")
            traceback.print_exc()
            progress_bar.progress(1.0, text="× ×›×©×œ")
            return None


# ×”×•×¡×¤×ª ×¤×•× ×§×¦×™×” ×—×“×©×” ×œ×™×¦×™×¨×ª ×¤×¨×•××¤×˜ ××—×™×“
def create_unified_prompt(base_prompt, segment_index, total_segments, is_processing=False):
    """×™×¦×™×¨×ª ×¤×¨×•××¤×˜ ××—×™×“ ×œ×›×œ ×©×œ×‘×™ ×”×ª×”×œ×™×š - ×ª××œ×•×œ ×•×¢×™×‘×•×“"""
    
    prompt = base_prompt

    # ×”×•×¡×¤×ª ××™×“×¢ ×¢×œ ×”××™×§×•× ×©×œ ×”××§×˜×¢
    if segment_index == 0:
        prompt += "\n\n×–×”×• ×”×—×œ×§ ×”×¨××©×•×Ÿ ×©×œ ×”×©×™×¢×•×¨."
    elif segment_index == total_segments - 1:
        prompt += f"\n\n×–×”×• ×”×—×œ×§ ×”××—×¨×•×Ÿ ×©×œ ×”×©×™×¢×•×¨ (×—×œ×§ {segment_index+1} ××ª×•×š {total_segments})."
    else:
        prompt += f"\n\n×–×”×• ×—×œ×§ ×××¦×¢×™ ×©×œ ×”×©×™×¢×•×¨ (×—×œ×§ {segment_index+1} ××ª×•×š {total_segments})."
    
    # ×× ×–×” ×¢×‘×•×¨ ×©×œ×‘ ×”×¢×™×‘×•×“, ×”×•×¡×£ ×”× ×—×™×” ×¡×¤×¦×™×¤×™×ª ×œ×¢×™×‘×•×“
    if is_processing:
        prompt += "\n\n× × ×œ×¢×‘×“ ××ª ×”×˜×§×¡×˜ ×”×’×•×œ××™ ×œ×ª××œ×•×œ × ×§×™ ×•××“×•×™×§ ×ª×•×š ×©××™×¨×” ×§×¤×“× ×™×ª ×¢×œ ×›×œ ×”×”× ×—×™×•×ª ×œ×¢×™×œ."
    
    return prompt

# ×¢×“×›×•×Ÿ ×‘×¤×•× ×§×¦×™×” process_segments:
def process_segments(api_key, model, token_manager, project_ids, segments, temp_dir, 
                    custom_prompt, progress_bar, status_text, num_segments):
    """×¢×™×‘×•×“ ×›×œ ××§×˜×¢ ××•×“×™×• ×‘×××¦×¢×•×ª ×ª××œ×•×œ ×•×¢×™×‘×•×“ LLM."""
    
    # ×¤×¨×•××¤×˜ ×ª××œ×•×œ ××•×ª×× ××™×©×™×ª ××• ×¤×¨×•××¤×˜ ×‘×¨×™×¨×ª ××—×“×œ
    if not custom_prompt or custom_prompt.strip() == "":
        # ×¤×¨×•××¤×˜ ×ª××œ×•×œ ×‘×¨×™×¨×ª ××—×“×œ
        base_transcription_prompt = """# ×ª×¤×§×™×“×š ×”×•× ×ª××œ×•×œ ××§×¦×•×¢×™ ×©×œ ×©×™×¢×•×¨×™ ×ª×•×¨×” ×¢× ×“×’×© ×¢×œ ×“×™×•×§ ×‘×¤×¨×˜×™×
## ××˜×¨×”
××ª×” ××ª××œ×œ ××§×¦×•×¢×™ ×”××ª××—×” ×‘×ª××œ×•×œ ×©×™×¢×•×¨×™ ×ª×•×¨×” ×‘×¢×‘×¨×™×ª. ×¢×œ×™×š ×œ×™×™×¦×¨ ×˜×§×¡×˜ ××“×•×™×§ ×‘××™×•×—×“ ×ª×•×š ×©×™××•×© ×‘×”×§×©×¨ ×œ×”×‘× ×” × ×›×•× ×” ×©×œ ××™×œ×™×, ×©××•×ª ×•××•× ×—×™×.

## ×”× ×—×™×•×ª ×œ×“×™×•×§ ××‘×•×¡×¡ ×”×§×©×¨
### ×©××•×ª ×•××•×©×’×™×
- ×”×§×“×© ×ª×©×•××ª ×œ×‘ ××™×•×—×“×ª ×œ×©××•×ª ×©×œ ×¨×‘× ×™×, ×¤×¨×©× ×™×, ×¡×¤×¨×™×, ×•×—×›××™ ×ª×•×¨×”
- ×”×©×ª××© ×‘×”×§×©×¨ ×”×©×™×¢×•×¨ ×›×“×™ ×œ×–×”×•×ª × ×›×•×Ÿ ×©××•×ª ×•××•× ×—×™× ×©× ×©××¢×™× ×œ× ×‘×¨×•×¨×™×
- ×›×©××ª×” × ×ª×§×œ ×‘××™×œ×™× ×œ× ×‘×¨×•×¨×•×ª, ×”×ª×™×™×—×¡ ×œ×”×§×©×¨ ×”××©×¤×˜, × ×•×©× ×”×©×™×—×”, ×•×”×˜×¨××™× ×•×œ×•×’×™×” ×”××ª××™××”
- ×”×™×” ×–×”×™×¨ ×‘××™×•×—×“ ×¢× ××™×œ×™× ×”×•××•×¤×•× ×™×•×ª ×‘×¢×‘×¨×™×ª (××™×œ×™× ×©× ×©××¢×•×ª ×“×•××”) ×•×‘×—×¨ ××ª ×”××©××¢×•×ª ×”× ×›×•× ×” ×¢×œ ×¤×™ ×”×”×§×©×¨
- ×¢×‘×•×¨ ××•× ×—×™× ××§×¦×•×¢×™×™× (××•× ×—×™ ×”×œ×›×”, ××•×©×’×™ ×™×©×™×‘×” ×•×›×•'), ×”×©×ª××© ×‘×™×“×¢ ×©×œ×š ×›×“×™ ×œ×–×”×•×ª ××•×ª× ×‘××“×•×™×§
- ×× ×”×“×™×•×Ÿ ×¢×•×¡×§ ×‘×¤×¨×©× ×•×ª ××• ×˜×§×¡×˜ ××¡×•×™×, ×•×“× ×©×”××•× ×—×™× ×”×§×©×•×¨×™× ××ª×•××œ×œ×™× ×‘×¦×•×¨×” ××“×•×™×§×ª
- ×©×™× ×œ×‘ ×œ×”×‘×—× ×•×ª ×‘×™×Ÿ ×¢×‘×¨×™×ª ×œ××¨××™×ª ×‘×¦×™×˜×•×˜×™×

### ×“×™×•×§ ×‘×¦×™×˜×•×˜×™× ××”××§×•×¨×•×ª
- ×”×™×” ××“×•×™×§ ×‘××™×•×—×“ ×‘×¦×™×˜×•×˜×™ ×¤×¡×•×§×™× ××”×ª× "×š
- ×”×§×¤×“ ×¢×œ ×“×™×•×§ ×‘×¦×™×˜×•×˜×™× ××—×–"×œ, ×’××¨×, ××©× ×” ×•×”×œ×›×”
- ×¡××Ÿ ×¦×™×˜×•×˜×™× ×‘××™×¨×›××•×ª ×•×ª×§×Ÿ ×©×’×™××•×ª ×§×œ×•×ª ×‘×¦×™×˜×•×˜ ×× ×™×©× ×Ÿ
- ×”×ª×™×™×—×¡ ×œ×”×§×©×¨ ×”×ª×•×›×Ÿ ×›×“×™ ×œ×”×‘×™×Ÿ × ×›×•×Ÿ ×¦×™×˜×•×˜×™× ×—×œ×§×™×™× ××• ××¨×•××–×™×

### ×”×‘×—× ×” ×‘×™×Ÿ ×“×•×‘×¨×™×
- ×”×‘×—×Ÿ ×‘×‘×™×¨×•×¨ ×‘×™×Ÿ ×“×‘×¨×™ ×”×¨×‘ ×œ×©××œ×•×ª ×”×§×”×œ
- ×¡××Ÿ ×©××œ×•×ª ××”×§×”×œ ×‘×¤×•×¨××˜: [×©××œ×” ××”×§×”×œ]: ×ª×•×›×Ÿ ×”×©××œ×”
- ×¡××Ÿ ××ª ×ª×©×•×‘×ª ×”×¨×‘ ×‘×¤×•×¨××˜: [×”×¨×‘]: ×ª×•×›×Ÿ ×”×ª×©×•×‘×”
- ×× ×™×© ×“×•-×©×™×— ××¨×•×š, ×”××©×š ×œ×¡××Ÿ ×›×œ ×—×™×œ×•×¤×™ ×“×‘×¨×™×

### ×ª×™×§×•× ×™× ×—×›××™×
- ×”×¡×¨ ×—×–×¨×•×ª ××™×•×ª×¨×•×ª ×•××™×œ×•×ª ××™×œ×•×™ ××š ×©××•×¨ ×¢×œ ×“×™×•×§ ×‘×ª×•×›×Ÿ
- ×ª×§×Ÿ ×©×’×™××•×ª ×“×™×‘×•×¨ ×¨×§ ×›××©×¨ ×‘×¨×•×¨ ××”×”×§×©×¨ ××” ×”×›×•×•× ×” ×”×××™×ª×™×ª
- ×©××•×¨ ×¢×œ ×”××©××¢×•×ª ×”××“×•×™×§×ª ×’× ×›×©××ª×” ×× ×¡×— ××—×“×© ××©×¤×˜×™× ×œ× ×‘×¨×•×¨×™×
- ×‘×”×ª×œ×‘×˜×•×ª ×‘×™×Ÿ ×©×ª×™ ××¤×©×¨×•×™×•×ª ×¤×™×¨×•×©, ×‘×—×¨ ××ª ×–×• ×”××ª××™××” ×™×•×ª×¨ ×œ×”×§×©×¨ ×”×ª×•×›×Ÿ

## ××” ×œ× ×œ×¢×©×•×ª
- ××œ ×ª× ×—×© ×©××•×ª ××• ××•× ×—×™× ×›×©××ª×” ×œ× ×‘×˜×•×—, ×‘××§×•× ×–××ª ×”×©×ª××© ×‘×”×§×©×¨ ×œ×”×‘× ×” ×˜×•×‘×” ×™×•×ª×¨
- ××œ ×ª×•×¡×™×£ ×¤×¨×©× ×•×ª ××• ×”×¡×‘×¨×™× ××©×œ×š
- ××œ ×ª×©× ×” ××ª ×¡×’× ×•×Ÿ ×”×“×™×‘×•×¨ ×©×œ ×”×¨×‘
- ××œ ×ª×©××™×˜ ×“×•×’×××•×ª, ××•× ×—×™× ××§×¦×•×¢×™×™× ××• ×¦×™×˜×•×˜×™× ××•×¨×›×‘×™× ×’× ×× ×”× ×§×©×™× ×œ×”×‘× ×”

## ×¤×•×¨××˜ ×”×¤×œ×˜ ×”×¡×•×¤×™
×”×’×© ××ª ×”×ª××œ×•×œ ×›×˜×§×¡×˜ ×¨×¦×™×£ ×¢× ×—×œ×•×§×” ×˜×‘×¢×™×ª ×œ×¤×¡×§××•×ª. ×”×©×ª××© ×‘×¨×•×•×—×™× ×‘×™×Ÿ × ×•×©××™× ×©×•× ×™× ×•×©××•×¨ ×¢×œ ×¡×“×¨ ×”×’×™×•× ×™ ×©×œ ×”×¨×¢×™×•× ×•×ª.

× × ×œ×ª××œ×œ ××ª ×”×”×§×œ×˜×” ×”××¦×•×¨×¤×ª ×‘××•×¤×Ÿ ××“×•×™×§ ×œ×¤×™ ×”×”× ×—×™×•×ª ×œ×¢×™×œ."""
    else:
        # ×©×™××•×© ×‘×¤×¨×•××¤×˜ ××•×ª×× ××™×©×™×ª
        base_transcription_prompt = custom_prompt
    
    # ×‘×—×™×¨×ª ×¤×¨×•×™×§×˜ ××—×“ ×œ×›×œ ×”×ª×”×œ×™×š ×œ×”×‘×˜×—×ª ×¢×§×‘×™×•×ª
    primary_project = token_manager.get_available_project(project_ids)
    if not primary_project:
        status_text.error("×œ× × ××¦××• ×¤×¨×•×™×§×˜×™× ×¢× ××›×¡×ª ×˜×•×§× ×™× ×–××™× ×”. × ×¡×” ×©×•×‘ ××—×¨.")
        return None
    
    status_text.info(f"××©×ª××© ×‘×¤×¨×•×™×§×˜ {primary_project} ×‘××•×¤×Ÿ ×¢×§×‘×™ ×œ×›×œ ×”×ª×”×œ×™×š")
    
    # ×™×¦×™×¨×ª ×§×•×‘×¥ ×œ×•×’ ×œ×ª×™×¢×•×“ ×”×¤×¨×•××¤×˜×™×
    log_file = os.path.join(temp_dir, "prompts_log.txt")
    
    # ×¤×•× ×§×¦×™×” ×œ×ª×™×¢×•×“ ×”×¤×¨×•××¤×˜×™×
    def log_prompt(segment_num, prompt_type, prompt_text):
        with open(log_file, "a", encoding="utf-8") as f:
            timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            f.write(f"[{timestamp}] --- ××§×˜×¢ {segment_num} - {prompt_type} ---\n")
            f.write(prompt_text + "\n\n")
    
    processed_transcriptions = []
    
    for i, segment_file in enumerate(segments):
        status_text.info(f"\n××¢×‘×“ ××§×˜×¢ {i+1}/{len(segments)}")
        
        # ×©×œ×‘ 1: ×ª××œ×•×œ ×™×©×™×¨×•×ª ×¢× Gemini
        raw_file = os.path.join(temp_dir, f"raw_{i:03d}.txt")
        
        # ×‘×“×™×§×” ×× ×ª××œ×•×œ ×’×•×œ××™ ×›×‘×¨ ×§×™×™× (×œ×”××©×š ×¢×™×‘×•×“ ×©×”×•×¤×¡×§)
        if os.path.exists(raw_file):
            with open(raw_file, "r", encoding="utf-8") as f:
                raw_text = f.read()
            status_text.info(f"  ××©×ª××© ×‘×ª××œ×•×œ ×’×•×œ××™ ×§×™×™×: {len(raw_text)} ×ª×•×•×™×")
        else:
            try:
                status_text.info(f"  ××©×ª××© ×‘×¤×¨×•×™×§×˜ {primary_project} ×œ×ª××œ×•×œ")
                
                # ×˜×¢×™× ×ª ×§×•×‘×¥ ××•×“×™×•
                with open(segment_file, "rb") as audio_file:
                    audio_content = audio_file.read()
                
                # ×‘×“×™×§×ª ×’×•×“×œ ×§×•×‘×¥
                file_size = len(audio_content)
                status_text.info(f"  ×’×•×“×œ ×§×•×‘×¥ ××•×“×™×•: {file_size / 1024 / 1024:.2f} MB")
                
                # ×™×¦×™×¨×ª ×¤×¨×•××¤×˜ ××—×™×“ ×œ×ª××œ×•×œ
                transcription_prompt = create_unified_prompt(
                    base_transcription_prompt, i, len(segments), is_processing=False
                )
                
                # ×ª×™×¢×•×“ ×”×¤×¨×•××¤×˜
                log_prompt(i+1, "×¤×¨×•××¤×˜ ×ª××œ×•×œ", transcription_prompt)
                
                # ×¢×“×›×•×Ÿ ××“ ×”×ª×§×“××•×ª
                segment_progress_base = 1/3  # ×”×—×œ×§ ×”×¨××©×•×Ÿ ×©×œ ×”×ª×”×œ×™×š (×—×œ×•×§×”) ×”×•×©×œ×
                segment_progress = segment_progress_base + (i / len(segments)) / 3  # ×©×œ×™×© ×©× ×™ ×©×œ ×”×ª×”×œ×™×š
                progress_bar.progress(segment_progress, text=f"××ª××œ×œ ××§×˜×¢ {i+1}/{len(segments)}...")
                
                # ×§×¨×™××” ×œ-API ×©×œ Gemini ×¢× ×§×•×‘×¥ ×”××•×“×™×• ×›× ×¡×¤×—
                raw_text = transcribe_with_gemini(api_key, model, transcription_prompt, audio_content, progress_bar)
                
                # ××•××“×Ÿ ×˜×•×§× ×™× ×¢×œ ×¡××š ××©×š ×”××•×“×™×• (××•××“×Ÿ ×’×¡)
                segment_duration_seconds = len(AudioSegment.from_mp3(segment_file)) / 1000
                estimated_tokens = int(segment_duration_seconds * 5)  # ××•××“×Ÿ ×’×¡: 5 ×˜×•×§× ×™× ×œ×©× ×™×™×”
                
                # ×¨×™×©×•× ×©×™××•×© ×‘×˜×•×§× ×™×
                token_manager.record_usage(primary_project, estimated_tokens)
                
                # ×©××™×¨×ª ×”×ª××œ×•×œ ×”×’×•×œ××™
                with open(raw_file, "w", encoding="utf-8") as f:
                    f.write(raw_text)
                
                status_text.info(f"  ×ª××œ×•×œ ×”×•×©×œ×: {len(raw_text)} ×ª×•×•×™×")
            except Exception as e:
                error_msg = f"×©×’×™××” ×‘×ª××œ×•×œ ××§×˜×¢ {i+1}: {str(e)}"
                status_text.error(f"  {error_msg}")
                raw_text = f"[×©×’×™××”: {error_msg}]"
                
                # ×©××™×¨×ª ×”×•×“×¢×ª ×©×’×™××”
                with open(raw_file, "w", encoding="utf-8") as f:
                    f.write(raw_text)
        
        # ×©×œ×‘ 2: ×¢×™×‘×•×“ ×¢× Generative AI ×©×œ Gemini
        proc_file = os.path.join(temp_dir, f"processed_{i:03d}.txt")
        
        # ×‘×“×™×§×” ×× ×ª××œ×•×œ ××¢×•×‘×“ ×›×‘×¨ ×§×™×™×
        if os.path.exists(proc_file):
            with open(proc_file, "r", encoding="utf-8") as f:
                processed_text = f.read()
            status_text.info(f"  ××©×ª××© ×‘×ª××œ×•×œ ××¢×•×‘×“ ×§×™×™×: {len(processed_text)} ×ª×•×•×™×")
        else:
            try:
                status_text.info(f"  ××©×ª××© ×‘×¤×¨×•×™×§×˜ {primary_project} ×œ×¢×™×‘×•×“ ×˜×§×¡×˜ ×¢× ××•×“×œ: {model}")
                
                # ×™×¦×™×¨×ª ×¤×¨×•××¤×˜ ××—×™×“ ×œ×¢×™×‘×•×“ - ××•×ª×• ×¤×¨×•××¤×˜ ×‘×¡×™×¡×™ ×¢× ×ª×•×¡×¤×ª ×”× ×—×™×•×ª ×¢×™×‘×•×“
                processing_prompt = create_unified_prompt(
                    base_transcription_prompt, i, len(segments), is_processing=True
                )
                
                # ×ª×™×¢×•×“ ×”×¤×¨×•××¤×˜
                log_prompt(i+1, "×¤×¨×•××¤×˜ ×¢×™×‘×•×“", processing_prompt)
                
                # ×”×›× ×ª ×”×¤×¨×•××¤×˜ ×”××œ× ×›×•×œ×œ ×”×˜×§×¡×˜ ×”×’×•×œ××™
                full_prompt = f"{processing_prompt}\n\n×˜×§×¡×˜ ×’×•×œ××™ ×œ×¢×™×‘×•×“:\n{raw_text}"
                
                # ××•××“×Ÿ ×¡×¤×™×¨×ª ×˜×•×§× ×™× (××•××“×Ÿ ×’×¡: 1.5 ×˜×•×§× ×™× ×œ×ª×•)
                estimated_input_tokens = int(len(full_prompt) * 1.5)
                estimated_output_tokens = int(len(raw_text) * 2)  # ×¤×œ×˜ ×¢×©×•×™ ×œ×”×™×•×ª ×’×“×•×œ ×™×•×ª×¨ ×‘×’×œ×œ ×¤×•×¨××˜
                estimated_total_tokens = estimated_input_tokens + estimated_output_tokens
                
                # ×¢×“×›×•×Ÿ ××“ ×”×ª×§×“××•×ª
                processing_progress_base = 2/3  # ×©× ×™ ×—×œ×§×™× ×¨××©×•× ×™× ×©×œ ×”×ª×”×œ×™×š (×—×œ×•×§×” ×•×ª××œ×•×œ) ×”×•×©×œ××•
                processing_progress = processing_progress_base + (i / len(segments)) / 3  # ×©×œ×™×© ××—×¨×•×Ÿ ×©×œ ×”×ª×”×œ×™×š
                progress_bar.progress(processing_progress, text=f"××¢×‘×“ ×ª××œ×•×œ ××§×˜×¢ {i+1}/{len(segments)}...")
                
                # ×§×¨×™××” ×™×©×™×¨×” ×œ-API ×©×œ Gemini
                gemini_url = f"https://generativelanguage.googleapis.com/v1beta/models/{model}:generateContent?key={api_key}"
                
                payload = {
                    "contents": [{"parts": [{"text": full_prompt}]}],
                    "generationConfig": {
                        "temperature": 0.3,
                        "maxOutputTokens": 8192
                    }
                }
                
                response = requests.post(gemini_url, json=payload)
                
                if response.status_code != 200:
                    raise Exception(f"×‘×§×©×ª API × ×›×©×œ×” ×¢× ×§×•×“ {response.status_code}: {response.text}")
                
                response_data = response.json()
                processed_text = response_data["candidates"][0]["content"]["parts"][0]["text"]
                
                # ×¨×™×©×•× ×©×™××•×© ×‘×˜×•×§× ×™×
                token_manager.record_usage(primary_project, estimated_total_tokens)
                
                # ×©××™×¨×ª ×˜×§×¡×˜ ××¢×•×‘×“
                with open(proc_file, "w", encoding="utf-8") as f:
                    f.write(processed_text)
                
                status_text.info(f"  ×¢×™×‘×•×“ ×”×•×©×œ×: {len(processed_text)} ×ª×•×•×™×")
                
            except Exception as e:
                error_msg = f"×©×’×™××” ×‘×¢×™×‘×•×“ ××§×˜×¢ {i+1} ×¢× LLM: {str(e)}"
                status_text.error(f"  {error_msg}")
                processed_text = f"[×©×’×™××”: {error_msg}]\n\n{raw_text}"
                
                # ×©××™×¨×ª ×”×•×“×¢×ª ×©×’×™××” ×•×˜×§×¡×˜ ×’×•×œ××™ ×›×—×œ×•×¤×”
                with open(proc_file, "w", encoding="utf-8") as f:
                    f.write(processed_text)
        
        processed_transcriptions.append(processed_text)
        
        # ×”×©×”×™×” ×œ×× ×™×¢×ª ××’×‘×œ×•×ª ×§×¦×‘
        if i < len(segments) - 1:
            status_text.info("  ×”×©×”×™×” ×œ×× ×™×¢×ª ××’×‘×œ×•×ª ×§×¦×‘...")
            time.sleep(2)
    
    # ×‘×¡×™×•× ×”×¢×™×‘×•×“, ×©××™×¨×ª ×¡×™×›×•× ×©×œ ×›×œ ×”×¤×¨×•××¤×˜×™× ×©×©×™××©×•
    with open(os.path.join(temp_dir, "prompts_summary.txt"), "w", encoding="utf-8") as f:
        f.write(f"×‘×¡×™×¡ ×”×¤×¨×•××¤×˜: {base_transcription_prompt}\n\n")
        f.write(f"×¤×¨×•×™×§×˜ ×‘×©×™××•×©: {primary_project}\n")
        f.write(f"××¡×¤×¨ ××§×˜×¢×™×: {len(segments)}\n")
    
    return processed_transcriptions

def combine_transcriptions(processed_transcriptions, progress_bar, status_text):
    """×©×™×œ×•×‘ ×ª××œ×•×œ×™× ××¢×•×‘×“×™× ×œ××¡××š ××—×“ ×§×•×”×¨× ×˜×™."""
    status_text.info("\n××©×œ×‘ ×ª××œ×•×œ×™×...")
    progress_bar.progress(0.95, text="××©×œ×‘ ××ª ×›×œ ×”××§×˜×¢×™×...")
    
    if not processed_transcriptions:
        status_text.error("××™×Ÿ ×ª××œ×•×œ×™× ×–××™× ×™× ×œ×©×™×œ×•×‘")
        return None
    
    # ×¢×‘×•×¨ ××§×˜×¢ ×™×—×™×“, ×¤×©×•×˜ ×œ×”×©×ª××© ×‘×• ×™×©×™×¨×•×ª
    if len(processed_transcriptions) == 1:
        combined_text = processed_transcriptions[0]
    else:
        # ××§×˜×¢ ×¨××©×•×Ÿ ×›× ×§×•×“×ª ×”×ª×—×œ×”
        combined_text = processed_transcriptions[0]
        
        # ×¢×™×‘×•×“ ××§×˜×¢×™× × ×•×¡×¤×™× - ×’×™×©×” ×¤×©×•×˜×” ×™×•×ª×¨ ×œ×œ× ×–×™×”×•×™ ××§×˜×¢×™×
        for i, segment in enumerate(processed_transcriptions[1:], 1):
            status_text.info(f"  ××©×œ×‘ ××§×˜×¢ {i+1}/{len(processed_transcriptions)}...")
            
            # × ×™×§×•×™ ×©×•×¨×•×ª ×—×•×–×¨×•×ª ×‘×ª×—×™×œ×” ×©×¢×©×•×™×•×ª ×œ×—×¤×•×£ ×¢× ×”××§×˜×¢ ×”×§×•×“×
            segment_text = segment.strip()
            
            # ×”×•×¡×¤×ª ××¢×‘×¨ ×¤×¡×§×” ×× ×¦×¨×™×š
            if not combined_text.endswith('\n\n'):
                combined_text += '\n\n'
                
            # ×¤×©×•×˜ ×”×•×¡×¤×ª ×”××§×˜×¢
            combined_text += segment_text
    
    status_text.info(f"  ××•×¨×š ×›×•×œ×œ: {len(combined_text)} ×ª×•×•×™×")
    return combined_text


def run_transcription_app():
    """×”×¤×•× ×§×¦×™×” ×”×¨××©×™×ª ×œ×”×¤×¢×œ×ª ×”××¤×œ×™×§×¦×™×”"""
    
    st.sidebar.markdown("""
    <script>
    // ×¤×•× ×§×¦×™×” ×œ×˜×¢×™× ×ª × ×ª×•× ×™× ×××—×¡×•×Ÿ ××§×•××™
    function loadFromLocalStorage() {
        if (localStorage.getItem('remember_me') === 'true') {
            const api_key = localStorage.getItem('api_key') || '';
            const projects = localStorage.getItem('projects') || '';
            
            // ×©×œ×™×—×ª ×”×¢×¨×›×™× ×œ××¦×‘ ×”×ª×–×¨×™× (session)
            window.parent.postMessage({
                type: 'streamlit:setComponentValue',
                componentName: 'streamlit_js_eval',
                value: {
                    api_key: api_key,
                    projects: projects,
                    remember_me: true
                }
            }, '*');
        }
    }

    // ×¤×•× ×§×¦×™×” ×œ×©××™×¨×ª × ×ª×•× ×™× ×‘××—×¡×•×Ÿ ××§×•××™
    function saveToLocalStorage(remember, api_key, projects) {
        if (remember) {
            localStorage.setItem('remember_me', 'true');
            localStorage.setItem('api_key', api_key);
            localStorage.setItem('projects', projects);
        } else {
            localStorage.removeItem('remember_me');
            localStorage.removeItem('api_key');
            localStorage.removeItem('projects');
        }
    }

    // ×˜×¢×™× ×ª × ×ª×•× ×™× ×‘×¢×ª ×˜×¢×™× ×ª ×”×“×£
    document.addEventListener('DOMContentLoaded', loadFromLocalStorage);
    </script>
    """, unsafe_allow_html=True)
    # ×¡×¨×’×œ ×¦×“ ×¢× ×”×’×“×¨×•×ª
    st.sidebar.header("×”×’×“×¨×•×ª ×ª××œ×•×œ")
    
    # × ×™×¡×™×•×Ÿ ×œ×˜×¢×•×Ÿ × ×ª×•× ×™× ×©××•×¨×™×
   # × ×™×¡×™×•×Ÿ ×œ×˜×¢×•×Ÿ × ×ª×•× ×™× ×©××•×¨×™× ×‘×××¦×¢×•×ª eval_js
    remember_me_js = streamlit_js_eval(js_expressions="localStorage.getItem('remember_me')")
        
    if 'remember_me' not in st.session_state:
        st.session_state.remember_me = False
        
    if remember_me_js == 'true':
        st.session_state.remember_me = True
        api_key_js = streamlit_js_eval(js_expressions="localStorage.getItem('api_key')")
        projects_js = streamlit_js_eval(js_expressions="localStorage.getItem('projects')")
        
        if api_key_js:
            st.session_state.api_key = api_key_js
        if projects_js:
            st.session_state.projects = projects_js

    # ×”×’×“×¨×•×ª API
    api_key = st.sidebar.text_input(
        "××¤×ª×— API ×©×œ Google AI Studio",
        type="password",
        value=st.session_state.get('api_key', '')
    )

    projects = st.sidebar.text_input(
        "××–×”×™ ×¤×¨×•×™×§×˜×™× ×©×œ Google Cloud (××•×¤×¨×“×™× ×‘×¤×¡×™×§×™×)",
        value=st.session_state.get('projects', 'project-1,project-2')
    )

    remember_me = st.sidebar.checkbox("×–×›×•×¨ ××•×ª×™", value=st.session_state.get('remember_me', False))

    # ×©××™×¨×” ×‘×–×™×›×¨×•×Ÿ ×”××§×•××™ ×‘×©×™× ×•×™
    if remember_me:
        streamlit_js_eval.run_js(f"""
        saveToLocalStorage(true, '{api_key}', '{projects}');
        """)
    else:
        streamlit_js_eval.run_js("""
        saveToLocalStorage(false, '', '');
        """)

    # ×¢×“×›×•×Ÿ ××¦×‘ ×”×ª×–×¨×™×
    st.session_state.api_key = api_key
    st.session_state.projects = projects
    st.session_state.remember_me = remember_me

    model = st.sidebar.selectbox("××•×“×œ Google AI", 
                                ["gemini-2.0-flash", "gemini-1.5-flash", "gemini-1.5-pro"], 
                                index=0)
    
    # ×”×’×“×¨×•×ª ××§×˜×¢×™×
    with st.sidebar.expander("×”×’×“×¨×•×ª ××ª×§×“××•×ª"):
        segment_length = st.number_input("××•×¨×š ××§×˜×¢ ××§×¡×™××œ×™ (×“×§×•×ª)", 
                                        min_value=1, max_value=60, value=25)
        overlap = st.number_input("×—×¤×™×¤×” ×‘×™×Ÿ ××§×˜×¢×™× (×©× ×™×•×ª)", 
                                 min_value=0, max_value=300, value=30)
    
    # ××™×“×¢ ×¢×œ ×©×™××•×©
    st.sidebar.markdown("---")
    st.sidebar.markdown("""
    ### ×›×™×¦×“ ×œ×”×©×ª××©
    1. ×”×–×Ÿ ××¤×ª×— API ×©×œ Google AI Studio
    2. ×”×–×Ÿ ××–×”×™ ×¤×¨×•×™×§×˜×™× (×œ× ×™×”×•×œ ××›×¡×•×ª ×˜×•×§× ×™×)
    3. ×”×¢×œ×” ×§×•×‘×¥ MP3
    4. ×”×ª×× ××ª ×”×¤×¨×•××¤×˜ ×œ×¤×™ ×”×¦×•×¨×š
    5. ×œ×—×¥ ×¢×œ "×ª××œ×œ" ×•×”××ª×Ÿ ×œ×¡×™×•× ×”×ª×”×œ×™×š
    6. ×”×•×¨×“ ××ª ×”×ª××œ×•×œ ×”××œ× ×‘×¡×™×•×
    """)
    
    # Expander ×œ×¤×¨×•××¤×˜ ××•×ª×× ××™×©×™×ª
    with st.expander("×¤×¨×•××¤×˜ ××•×ª×× ××™×©×™×ª ×œ×ª××œ×•×œ", expanded=False):
        st.markdown("""
        ×›××Ÿ ×ª×•×›×œ ×œ×”×ª××™× ××ª ×”×”×•×¨××•×ª ×©×™×™×©×œ×—×• ×œ××•×“×œ ×”-AI ×œ×ª××œ×•×œ. 
        × ×™×ª×Ÿ ×œ×”×©××™×¨ ×¨×™×§ ×›×“×™ ×œ×”×©×ª××© ×‘×¤×¨×•××¤×˜ ×‘×¨×™×¨×ª ×”××—×“×œ ×©××•×ª×× ×œ×ª××œ×•×œ ×©×™×¢×•×¨×™ ×ª×•×¨×”.
        """)
        
        default_prompt = """# ×ª×¤×§×™×“×š ×”×•× ×ª××œ×•×œ ××§×¦×•×¢×™ ×©×œ ×©×™×¢×•×¨×™ ×ª×•×¨×” ×¢× ×“×’×© ×¢×œ ×“×™×•×§ ×‘×¤×¨×˜×™×
        ## ××˜×¨×”
        ××ª×” ××ª××œ×œ ××§×¦×•×¢×™ ×”××ª××—×” ×‘×ª××œ×•×œ ×©×™×¢×•×¨×™ ×ª×•×¨×” ×‘×¢×‘×¨×™×ª. ×¢×œ×™×š ×œ×™×™×¦×¨ ×˜×§×¡×˜ ××“×•×™×§ ×‘××™×•×—×“ ×ª×•×š ×©×™××•×© ×‘×”×§×©×¨ ×œ×”×‘× ×” × ×›×•× ×” ×©×œ ××™×œ×™×, ×©××•×ª ×•××•× ×—×™×.

        ## ×”× ×—×™×•×ª ×œ×“×™×•×§ ××‘×•×¡×¡ ×”×§×©×¨
        ### ×©××•×ª ×•××•×©×’×™×
        - ×”×§×“×© ×ª×©×•××ª ×œ×‘ ××™×•×—×“×ª ×œ×©××•×ª ×©×œ ×¨×‘× ×™×, ×¤×¨×©× ×™×, ×¡×¤×¨×™×, ×•×—×›××™ ×ª×•×¨×”
        - ×”×©×ª××© ×‘×”×§×©×¨ ×”×©×™×¢×•×¨ ×›×“×™ ×œ×–×”×•×ª × ×›×•×Ÿ ×©××•×ª ×•××•× ×—×™× ×©× ×©××¢×™× ×œ× ×‘×¨×•×¨×™×
        - ×›×©××ª×” × ×ª×§×œ ×‘××™×œ×™× ×œ× ×‘×¨×•×¨×•×ª, ×”×ª×™×™×—×¡ ×œ×”×§×©×¨ ×”××©×¤×˜, × ×•×©× ×”×©×™×—×”, ×•×”×˜×¨××™× ×•×œ×•×’×™×” ×”××ª××™××”
        - ×”×™×” ×–×”×™×¨ ×‘××™×•×—×“ ×¢× ××™×œ×™× ×”×•××•×¤×•× ×™×•×ª ×‘×¢×‘×¨×™×ª (××™×œ×™× ×©× ×©××¢×•×ª ×“×•××”) ×•×‘×—×¨ ××ª ×”××©××¢×•×ª ×”× ×›×•× ×” ×¢×œ ×¤×™ ×”×”×§×©×¨
        - ×¢×‘×•×¨ ××•× ×—×™× ××§×¦×•×¢×™×™× (××•× ×—×™ ×”×œ×›×”, ××•×©×’×™ ×™×©×™×‘×” ×•×›×•'), ×”×©×ª××© ×‘×™×“×¢ ×©×œ×š ×›×“×™ ×œ×–×”×•×ª ××•×ª× ×‘××“×•×™×§

        ### ×“×™×•×§ ×‘×¦×™×˜×•×˜×™× ××”××§×•×¨×•×ª
        - ×”×™×” ××“×•×™×§ ×‘××™×•×—×“ ×‘×¦×™×˜×•×˜×™ ×¤×¡×•×§×™× ××”×ª× "×š
        - ×”×§×¤×“ ×¢×œ ×“×™×•×§ ×‘×¦×™×˜×•×˜×™× ××—×–"×œ, ×’××¨×, ××©× ×” ×•×”×œ×›×”
        - ×¡××Ÿ ×¦×™×˜×•×˜×™× ×‘××™×¨×›××•×ª ×•×ª×§×Ÿ ×©×’×™××•×ª ×§×œ×•×ª ×‘×¦×™×˜×•×˜ ×× ×™×©× ×Ÿ

        ### ×”×‘×—× ×” ×‘×™×Ÿ ×“×•×‘×¨×™×
        - ×”×‘×—×Ÿ ×‘×‘×™×¨×•×¨ ×‘×™×Ÿ ×“×‘×¨×™ ×”×¨×‘ ×œ×©××œ×•×ª ×”×§×”×œ
        - ×¡××Ÿ ×©××œ×•×ª ××”×§×”×œ ×‘×¤×•×¨××˜: [×©××œ×” ××”×§×”×œ]: ×ª×•×›×Ÿ ×”×©××œ×”
        - ×¡××Ÿ ××ª ×ª×©×•×‘×ª ×”×¨×‘ ×‘×¤×•×¨××˜: [×”×¨×‘]: ×ª×•×›×Ÿ ×”×ª×©×•×‘×”

        ## ××” ×œ× ×œ×¢×©×•×ª
        - ××œ ×ª× ×—×© ×©××•×ª ××• ××•× ×—×™× ×›×©××ª×” ×œ× ×‘×˜×•×—, ×‘××§×•× ×–××ª ×”×©×ª××© ×‘×”×§×©×¨ ×œ×”×‘× ×” ×˜×•×‘×” ×™×•×ª×¨
        - ××œ ×ª×•×¡×™×£ ×¤×¨×©× ×•×ª ××• ×”×¡×‘×¨×™× ××©×œ×š
        - ××œ ×ª×©× ×” ××ª ×¡×’× ×•×Ÿ ×”×“×™×‘×•×¨ ×©×œ ×”×¨×‘
        """
        
        custom_prompt = st.text_area("×”×›× ×¡ ×¤×¨×•××¤×˜ ××•×ª×× ××™×©×™×ª", 
                                    value=default_prompt, 
                                    height=300)
    
    # ××–×•×¨ ×”×¢×œ××ª ×§×•×‘×¥
    st.markdown("## ×”×¢×œ××ª ×§×•×‘×¥ ××•×“×™×•")
    uploaded_file = st.file_uploader("×‘×—×¨ ×§×•×‘×¥ MP3 ×œ×ª××œ×•×œ", type=["mp3"])
    
    if uploaded_file is not None:
        st.audio(uploaded_file, format="audio/mp3")
        
        # ×›×¤×ª×•×¨ ×ª××œ×•×œ
        if st.button("×ª××œ×œ", type="primary"):
            if not api_key:
                st.error("× × ×œ×”×–×™×Ÿ ××¤×ª×— API ×©×œ Google AI Studio")
            elif not projects:
                st.error("× × ×œ×”×–×™×Ÿ ×œ×¤×—×•×ª ××–×”×” ×¤×¨×•×™×§×˜ ××—×“")
            else:
                # ×™×¦×™×¨×ª ××–×•×¨×™× ×œ×”×¦×’×ª ×”×ª×§×“××•×ª
                status_container = st.container()
                progress_bar = st.progress(0, text="××ª×—×™×œ...")
                
                with status_container:
                    status_text = st.empty()
                
                # ×”×¤×¢×œ×ª ×”×ª××œ×•×œ ×‘×ª×”×œ×™×š × ×¤×¨×“
                result = process_audio(
                    uploaded_file, api_key, projects, model,
                    segment_length, overlap, custom_prompt,
                    progress_bar, status_text
                )
                
                if result:
                    st.markdown("## ×ª×•×¦××•×ª ×”×ª××œ×•×œ")
                    st.text_area("×ª××œ×•×œ ××œ×", value=result, height=500)
                    
                    # ×”×•×¨×“×ª ×§×•×‘×¥
                    st.download_button(
                        label="×”×•×¨×“ ×›×§×•×‘×¥ ×˜×§×¡×˜",
                        data=result,
                        file_name=f"{uploaded_file.name.split('.')[0]}_transcription.txt",
                        mime="text/plain"
                    )

    # ×”×•×¡×¤×ª ×—×•×ª××ª ×‘×ª×—×ª×™×ª ×”×¢××•×“
    st.markdown("---")
    st.markdown(
        """
        <div style="text-align: center; margin-top: 30px; margin-bottom: 10px; direction: rtl;">
            <p style="color: #555; font-size: 0.9em; font-weight: bold;">
                × ×‘× ×” ×‘××”×‘×ª ×ª×•×¨×” ×¢"×™ Studio TASH ×œ×™×©×™×‘×ª ×©×™×¨×ª ××©×” ×™×¤×•
            </p>
        </div>
        """, 
        unsafe_allow_html=True
    )

if __name__ == "__main__":
    run_transcription_app()
