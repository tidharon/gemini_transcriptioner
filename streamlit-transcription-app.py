import streamlit as st
import os
import json
import datetime
import time
import requests
import base64
from pydub import AudioSegment
import shutil
import traceback
from io import BytesIO
import tempfile
import threading
import re

# ×”×’×“×¨×ª ×”×›×•×ª×¨×ª ×•×¡×’× ×•×Ÿ ×”××¤×œ×™×§×¦×™×”
st.set_page_config(
    page_title="××¢×¨×›×ª ×ª××œ×•×œ ×©×™×¢×•×¨×™ ×ª×•×¨×”",
    page_icon="ğŸ™ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ×›×•×ª×¨×ª ×¨××©×™×ª
st.title("××¢×¨×›×ª ×ª××œ×•×œ ×©×™×¢×•×¨×™ ×ª×•×¨×”")
st.markdown("### ×”××¢×¨×›×ª ×××¤×©×¨×ª ×ª××œ×•×œ ××•×˜×•××˜×™ ×©×œ ×©×™×¢×•×¨×™× ×¢× Google Gemini")

# ×¡×™×“×•×¨ ×›×™×•×•×Ÿ ×”×˜×§×¡×˜ ×œ×¢×‘×¨×™×ª
st.markdown("""
<style>
    body {
        direction: rtl;
        text-align: right;
    }
    .stTextInput, .stTextArea {
        direction: rtl;
        text-align: right;
    }
    .streamlit-expanderHeader {
        direction: rtl;
        text-align: right;
    }
    p, h1, h2, h3, h4, h5, h6, div {
        direction: rtl;
        text-align: right;
    }
    .stButton button {
        float: right;
    }
</style>
""", unsafe_allow_html=True)

class TokenUsageManager:
    """×× ×”×œ ×©×™××•×© ×‘×˜×•×§× ×™× ×‘×¤×¨×•×™×§×˜×™× ×©×•× ×™× ×©×œ Google AI Studio."""
    
    def __init__(self, usage_file="token_usage.json"):
        self.usage_file = usage_file
        self.usage_data = self._load_usage_data()
        
    def _load_usage_data(self):
        """×˜×¢×™× ×ª × ×ª×•× ×™ ×©×™××•×© ×‘×˜×•×§× ×™× ××§×•×‘×¥, ××• ×™×¦×™×¨×ª ×§×•×‘×¥ ×—×“×© ×× ×œ× ×§×™×™×."""
        if os.path.exists(self.usage_file):
            try:
                with open(self.usage_file, "r") as f:
                    return json.load(f)
            except Exception as e:
                st.warning(f"××–×”×¨×”: × ×›×©×œ ×‘×˜×¢×™× ×ª × ×ª×•× ×™ ×©×™××•×© ×‘×˜×•×§× ×™×: {e}")
        
        # ××‘× ×” ×‘×¨×™×¨×ª ××—×“×œ ×× ×”×§×•×‘×¥ ×œ× ×§×™×™× ××• ×œ× ×ª×§×™×Ÿ
        return {
            "projects": {},
            "last_updated": datetime.datetime.now().strftime("%Y-%m-%d")
        }
    
    def _save_usage_data(self):
        """×©××™×¨×ª × ×ª×•× ×™ ×©×™××•×© ×‘×˜×•×§× ×™× ×œ×§×•×‘×¥."""
        try:
            with open(self.usage_file, "w") as f:
                json.dump(self.usage_data, f, indent=2)
        except Exception as e:
            st.warning(f"××–×”×¨×”: × ×›×©×œ ×‘×©××™×¨×ª × ×ª×•× ×™ ×©×™××•×© ×‘×˜×•×§× ×™×: {e}")
    
    def reset_daily_counters_if_needed(self):
        """××™×¤×•×¡ ××•× ×” ×™×•××™ ×× ×”×ª××¨×™×š ×”×ª×—×œ×£."""
        today = datetime.datetime.now().strftime("%Y-%m-%d")
        last_updated = self.usage_data.get("last_updated", "")
        
        if today != last_updated:
            st.info(f"×–×•×”×” ×™×•× ×—×“×©. ×××¤×¡ ××ª ××•× ×™ ×”×©×™××•×© ×”×™×•××™ ×‘×˜×•×§× ×™×.")
            # ××™×¤×•×¡ ×©×™××•×© ×™×•××™ ×œ×›×œ ×”×¤×¨×•×™×§×˜×™×
            for project_id in self.usage_data["projects"]:
                if "daily_usage" in self.usage_data["projects"][project_id]:
                    self.usage_data["projects"][project_id]["daily_usage"] = 0
            
            self.usage_data["last_updated"] = today
            self._save_usage_data()
    
    def register_project(self, project_id, daily_limit=1000000):
        """×¨×™×©×•× ×¤×¨×•×™×§×˜ ×—×“×© ××• ×¢×“×›×•×Ÿ ×”××’×‘×œ×•×ª ×©×œ×•."""
        if project_id not in self.usage_data["projects"]:
            self.usage_data["projects"][project_id] = {
                "daily_limit": daily_limit,
                "daily_usage": 0,
                "total_usage": 0
            }
        else:
            # ×¢×“×›×•×Ÿ ××’×‘×œ×” ×™×•××™×ª ×× ×”×©×ª× ×ª×”
            self.usage_data["projects"][project_id]["daily_limit"] = daily_limit
        
        self._save_usage_data()
    
    def record_usage(self, project_id, tokens_used):
        """×¨×™×©×•× ×©×™××•×© ×‘×˜×•×§× ×™× ×œ×¤×¨×•×™×§×˜."""
        if project_id not in self.usage_data["projects"]:
            self.register_project(project_id)
        
        self.usage_data["projects"][project_id]["daily_usage"] += tokens_used
        self.usage_data["projects"][project_id]["total_usage"] += tokens_used
        
        self._save_usage_data()
    
    def get_available_project(self, project_ids):
        """××¦×™××ª ×¤×¨×•×™×§×˜ ×¢× ×˜×•×§× ×™× ×–××™× ×™× ××¨×©×™××” × ×ª×•× ×”."""
        self.reset_daily_counters_if_needed()
        
        for project_id in project_ids:
            if project_id not in self.usage_data["projects"]:
                # ×¤×¨×•×™×§×˜ ×—×“×©, ×¨×™×©×•× ××•×˜×•××˜×™
                self.register_project(project_id)
                return project_id
            
            project_data = self.usage_data["projects"][project_id]
            if project_data["daily_usage"] < project_data["daily_limit"]:
                return project_id
        
        return None
    
    def get_usage_summary(self):
        """×”×¦×’×ª ×¡×™×›×•× ×©×™××•×© ×‘×˜×•×§× ×™× ×‘×›×œ ×”×¤×¨×•×™×§×˜×™×."""
        self.reset_daily_counters_if_needed()
        
        summary = []
        for project_id, data in self.usage_data["projects"].items():
            remaining = data["daily_limit"] - data["daily_usage"]
            percent_used = (data["daily_usage"] / data["daily_limit"]) * 100 if data["daily_limit"] > 0 else 0
            
            summary.append({
                "project_id": project_id,
                "daily_limit": data["daily_limit"],
                "daily_usage": data["daily_usage"],
                "remaining": remaining,
                "percent_used": percent_used,
                "total_usage": data["total_usage"]
            })
        
        return summary


def transcribe_with_gemini(api_key, model, prompt, audio_bytes, progress_bar=None):
    """×ª××œ×•×œ ××•×“×™×• ×‘×××¦×¢×•×ª ×”-API ×©×œ Gemini"""
    
    # × ×§×•×“×ª ×§×¦×” ×©×œ ×”-API
    url = f"https://generativelanguage.googleapis.com/v1beta/models/{model}:generateContent?key={api_key}"
    
    # ×”×›× ×ª ×‘×§×©×” ××¨×•×‘×ª ×—×œ×§×™× - ×–×”×• ×”××‘× ×” ×”× ×“×¨×© ×œ×©×œ×™×—×ª ×§×‘×¦×™× ×œ-Gemini
    audio_b64 = base64.b64encode(audio_bytes).decode('utf-8')
    
    payload = {
        "contents": [
            {
                "parts": [
                    {"text": prompt},
                    {
                        "inline_data": {
                            "mime_type": "audio/mp3",
                            "data": audio_b64
                        }
                    }
                ]
            }
        ],
        "generationConfig": {
            "temperature": 0.1,  # ×˜××¤×¨×˜×•×¨×” × ××•×›×” ×œ×ª××œ×•×œ ××“×•×™×§ ×™×•×ª×¨
            "maxOutputTokens": 8192
        }
    }
    
    # ×‘×™×¦×•×¢ ×‘×§×©×” ×¢× ×œ×•×’×™×§×ª × ×™×¡×™×•×Ÿ ×—×•×–×¨
    max_retries = 3
    for retry in range(max_retries):
        try:
            response = requests.post(url, json=payload)
            
            if response.status_code == 200:
                break
            else:
                if progress_bar:
                    progress_bar.text(f"×©×’×™××ª API (× ×™×¡×™×•×Ÿ {retry+1}/{max_retries}): {response.status_code}")
                if retry < max_retries - 1:
                    time.sleep(2 * (retry + 1))  # ×”××ª× ×” ×’×“×œ×” ××§×¡×¤×•× × ×¦×™××œ×™×ª
        except Exception as e:
            if progress_bar:
                progress_bar.text(f"×©×’×™××ª ×‘×§×©×” (× ×™×¡×™×•×Ÿ {retry+1}/{max_retries}): {e}")
            if retry < max_retries - 1:
                time.sleep(2 * (retry + 1))
    
    if response.status_code != 200:
        raise Exception(f"×‘×§×©×ª Gemini × ×›×©×œ×” ×¢× ×§×•×“ {response.status_code}: {response.text}")
    
    # ×¤×¢× ×•×— ×”×ª×©×•×‘×”
    response_data = response.json()
    
    # ×—×™×œ×•×¥ ×”×ª××œ×•×œ ××”×ª×©×•×‘×”
    try:
        transcript = response_data["candidates"][0]["content"]["parts"][0]["text"]
        return transcript.strip()
    except (KeyError, IndexError) as e:
        if progress_bar:
            progress_bar.text(f"×©×’×™××” ×‘×¤×¢× ×•×— ×ª×©×•×‘×ª Gemini: {e}")
            progress_bar.text(f"××‘× ×” ×”×ª×©×•×‘×”: {json.dumps(response_data, indent=2)}")
        return ""


def process_audio(uploaded_file, api_key, projects, model, segment_length, overlap, custom_prompt, progress_bar, status_text):
    """×¢×™×‘×•×“ ×§×•×‘×¥ ××•×“×™×•: ×˜×¢×™× ×”, ×—×œ×•×§×”, ×ª××œ×•×œ ×•×©×™×œ×•×‘"""
    
    # ×™×¦×™×¨×ª ×× ×”×œ ×©×™××•×© ×‘×˜×•×§× ×™×
    token_manager = TokenUsageManager()
    
    # ×¨×™×©×•× ×›×œ ×”×¤×¨×•×™×§×˜×™×
    project_ids = [p.strip() for p in projects.split(",") if p.strip()]
    if not project_ids:
        status_text.error("×©×’×™××”: ×™×© ×œ×¡×¤×§ ×œ×¤×—×•×ª ××–×”×” ×¤×¨×•×™×§×˜ ××—×“ ×©×œ Google Cloud")
        return None
    
    for project_id in project_ids:
        token_manager.register_project(project_id)
    
    # ×”×¦×’×ª ×©×™××•×© ×‘×˜×•×§× ×™× ×œ×¤× ×™ ×”×ª×—×œ×”
    status_text.info("×©×™××•×© × ×•×›×—×™ ×‘×˜×•×§× ×™× ×‘×¤×¨×•×™×§×˜×™×:")
    for project in token_manager.get_usage_summary():
        status_text.info(f"  {project['project_id']}: {project['daily_usage']}/{project['daily_limit']} ×˜×•×§× ×™× ×‘×©×™××•×© ({project['percent_used']:.1f}%)")
    
    # ×™×¦×™×¨×ª ×¡×¤×¨×™×” ×–×× ×™×ª
    with tempfile.TemporaryDirectory() as temp_dir:
        status_text.info(f"× ×•×¦×¨×” ×¡×¤×¨×™×” ×–×× ×™×ª: {temp_dir}")
        
        try:
            # ×©××™×¨×ª ×”×§×•×‘×¥ ×”××•×¢×œ×” ×œ×“×™×¡×§
            mp3_path = os.path.join(temp_dir, "uploaded_audio.mp3")
            with open(mp3_path, "wb") as f:
                f.write(uploaded_file.getbuffer())
            
            status_text.info(f"××¢×‘×“ ×§×•×‘×¥ ××•×“×™×•: {uploaded_file.name}")
            
            # ×˜×¢×™× ×ª ×§×•×‘×¥ ×”××•×“×™×•
            try:
                status_text.info("×˜×•×¢×Ÿ ×§×•×‘×¥ ××•×“×™×•...")
                audio = AudioSegment.from_mp3(mp3_path)
                status_text.info(f"×§×•×‘×¥ ××•×“×™×• × ×˜×¢×Ÿ: {len(audio) / 1000 / 60:.2f} ×“×§×•×ª")
            except Exception as e:
                status_text.error(f"× ×›×©×œ ×‘×˜×¢×™× ×ª ×§×•×‘×¥ ×”××•×“×™×•: {e}. ×•×“× ×©×”×ª×§× ×ª ffmpeg ×•×©×”×•× × ××¦× ×‘-PATH ×©×œ×š.")
                return None
            
            # ×—×™×©×•×‘ ×’×•×“×œ ××§×˜×¢ ×•×—×¤×™×¤×” ×‘××™×œ×™×©× ×™×•×ª
            segment_length_ms = segment_length * 60 * 1000
            overlap_ms = overlap * 1000
            
            if segment_length_ms <= overlap_ms:
                status_text.error(f"××•×¨×š ×”××§×˜×¢ ({segment_length} ×“×§×•×ª) ×—×™×™×‘ ×œ×”×™×•×ª ×’×“×•×œ ××”×—×¤×™×¤×” ({overlap} ×©× ×™×•×ª)")
                return None
            
            # ×—×™×©×•×‘ ××¡×¤×¨ ×”××§×˜×¢×™×
            total_duration_ms = len(audio)
            effective_length_ms = segment_length_ms - overlap_ms
            num_segments = (total_duration_ms - overlap_ms + effective_length_ms - 1) // effective_length_ms
            
            status_text.info(f"×”××•×“×™×• ×™×—×•×œ×§ ×œ-{num_segments} ××§×˜×¢×™×:")
            status_text.info(f"- ×›×œ ××§×˜×¢: ××§×¡×™××•× {segment_length} ×“×§×•×ª")
            status_text.info(f"- ×—×¤×™×¤×” ×‘×™×Ÿ ××§×˜×¢×™×: {overlap} ×©× ×™×•×ª")
            
            # ×”×’×“×¨×ª ××“ ×”×ª×§×“××•×ª
            progress_bar.progress(0, text="××ª×—×™×œ ×¢×™×‘×•×“...")
            
            # ×™×¦×™×¨×ª ××§×˜×¢×™×
            segments = []
            for i in range(num_segments):
                start_ms = i * effective_length_ms
                end_ms = min(total_duration_ms, start_ms + segment_length_ms)
                
                # ×™×¦×•× ××§×˜×¢ ×œ×§×•×‘×¥ ×–×× ×™
                temp_file = os.path.join(temp_dir, f"segment_{i:03d}.mp3")
                status_text.info(f"×™×•×¦×¨ ××§×˜×¢ {i+1}/{num_segments}: {start_ms/1000/60:.2f}-{end_ms/1000/60:.2f} ×“×§×•×ª")
                
                # ×—×™×œ×•×¥ ××§×˜×¢ ×•×™×¦×•×
                segment = audio[start_ms:end_ms]
                segment.export(temp_file, format="mp3")
                segments.append(temp_file)
                
                # ×¢×“×›×•×Ÿ ××“ ×”×ª×§×“××•×ª - ×©×œ×‘ ×”×—×œ×•×§×” ×œ××§×˜×¢×™×
                segment_progress = (i + 1) / (num_segments * 3)  # ×©×œ×™×© ×¨××©×•×Ÿ ×©×œ ×”×ª×”×œ×™×š
                progress_bar.progress(segment_progress, text=f"×—×•×œ×§ ××§×˜×¢ {i+1}/{num_segments}...")
            
            # ×¢×™×‘×•×“ ×›×œ ××§×˜×¢
            processed_transcriptions = process_segments(
                api_key, model, token_manager, project_ids, 
                segments, temp_dir, custom_prompt, 
                progress_bar, status_text, num_segments
            )
            
            if not processed_transcriptions:
                status_text.error("×œ× ×”×¦×œ×—× ×• ×œ×§×‘×œ ×ª××œ×•×œ ×œ××£ ××§×˜×¢")
                return None
            
            # ×©×™×œ×•×‘ ×›×œ ×”×ª××œ×•×œ×™× ×”××¢×•×‘×“×™×
            combined_text = combine_transcriptions(processed_transcriptions, progress_bar, status_text)
            
            # ×”×¦×’ ×©×™××•×© ×‘×˜×•×§× ×™× ××¢×•×“×›×Ÿ
            status_text.info("\n×©×™××•×© ×‘×˜×•×§× ×™× ××¢×•×“×›×Ÿ ×œ××—×¨ ×¢×™×‘×•×“:")
            for project in token_manager.get_usage_summary():
                status_text.info(f"  {project['project_id']}: {project['daily_usage']}/{project['daily_limit']} ×˜×•×§× ×™× ×‘×©×™××•×© ({project['percent_used']:.1f}%)")
            
            progress_bar.progress(1.0, text="×”×•×©×œ× ×‘×”×¦×œ×—×”!")
            status_text.success("×ª××œ×•×œ ×”×§×•×‘×¥ ×”×•×©×œ× ×‘×”×¦×œ×—×”")
            
            return combined_text
            
        except Exception as e:
            status_text.error(f"×©×’×™××”: {str(e)}")
            traceback.print_exc()
            progress_bar.progress(1.0, text="× ×›×©×œ")
            return None


def process_segments(api_key, model, token_manager, project_ids, segments, temp_dir, 
                    custom_prompt, progress_bar, status_text, num_segments):
    """×¢×™×‘×•×“ ×›×œ ××§×˜×¢ ××•×“×™×• ×‘×××¦×¢×•×ª ×ª××œ×•×œ ×•×¢×™×‘×•×“ LLM."""
    
    # ×¤×¨×•××¤×˜ ×ª××œ×•×œ ××•×ª×× ××™×©×™×ª ××• ×¤×¨×•××¤×˜ ×‘×¨×™×¨×ª ××—×“×œ
    if not custom_prompt or custom_prompt.strip() == "":
        # ×¤×¨×•××¤×˜ ×ª××œ×•×œ ×‘×¨×™×¨×ª ××—×“×œ
        base_transcription_prompt = """# ×ª×¤×§×™×“×š ×”×•× ×ª××œ×•×œ ××§×¦×•×¢×™ ×©×œ ×©×™×¢×•×¨×™ ×ª×•×¨×” ×¢× ×“×’×© ×¢×œ ×“×™×•×§ ×‘×¤×¨×˜×™×
## ××˜×¨×”
××ª×” ××ª××œ×œ ××§×¦×•×¢×™ ×”××ª××—×” ×‘×ª××œ×•×œ ×©×™×¢×•×¨×™ ×ª×•×¨×” ×‘×¢×‘×¨×™×ª. ×¢×œ×™×š ×œ×™×™×¦×¨ ×˜×§×¡×˜ ××“×•×™×§ ×‘××™×•×—×“ ×ª×•×š ×©×™××•×© ×‘×”×§×©×¨ ×œ×”×‘× ×” × ×›×•× ×” ×©×œ ××™×œ×™×, ×©××•×ª ×•××•× ×—×™×.

## ×”× ×—×™×•×ª ×œ×“×™×•×§ ××‘×•×¡×¡ ×”×§×©×¨
### ×©××•×ª ×•××•×©×’×™×
- ×”×§×“×© ×ª×©×•××ª ×œ×‘ ××™×•×—×“×ª ×œ×©××•×ª ×©×œ ×¨×‘× ×™×, ×¤×¨×©× ×™×, ×¡×¤×¨×™×, ×•×—×›××™ ×ª×•×¨×”
- ×”×©×ª××© ×‘×”×§×©×¨ ×”×©×™×¢×•×¨ ×›×“×™ ×œ×–×”×•×ª × ×›×•×Ÿ ×©××•×ª ×•××•× ×—×™× ×©× ×©××¢×™× ×œ× ×‘×¨×•×¨×™×
- ×›×©××ª×” × ×ª×§×œ ×‘××™×œ×™× ×œ× ×‘×¨×•×¨×•×ª, ×”×ª×™×™×—×¡ ×œ×”×§×©×¨ ×”××©×¤×˜, × ×•×©× ×”×©×™×—×”, ×•×”×˜×¨××™× ×•×œ×•×’×™×” ×”××ª××™××”
- ×”×™×” ×–×”×™×¨ ×‘××™×•×—×“ ×¢× ××™×œ×™× ×”×•××•×¤×•× ×™×•×ª ×‘×¢×‘×¨×™×ª (××™×œ×™× ×©× ×©××¢×•×ª ×“×•××”) ×•×‘×—×¨ ××ª ×”××©××¢×•×ª ×”× ×›×•× ×” ×¢×œ ×¤×™ ×”×”×§×©×¨
- ×¢×‘×•×¨ ××•× ×—×™× ××§×¦×•×¢×™×™× (××•× ×—×™ ×”×œ×›×”, ××•×©×’×™ ×™×©×™×‘×” ×•×›×•'), ×”×©×ª××© ×‘×™×“×¢ ×©×œ×š ×›×“×™ ×œ×–×”×•×ª ××•×ª× ×‘××“×•×™×§
- ×× ×”×“×™×•×Ÿ ×¢×•×¡×§ ×‘×¤×¨×©× ×•×ª ××• ×˜×§×¡×˜ ××¡×•×™×, ×•×“× ×©×”××•× ×—×™× ×”×§×©×•×¨×™× ××ª×•××œ×œ×™× ×‘×¦×•×¨×” ××“×•×™×§×ª
- ×©×™× ×œ×‘ ×œ×”×‘×—× ×•×ª ×‘×™×Ÿ ×¢×‘×¨×™×ª ×œ××¨××™×ª ×‘×¦×™×˜×•×˜×™×

### ×“×™×•×§ ×‘×¦×™×˜×•×˜×™× ××”××§×•×¨×•×ª
- ×”×™×” ××“×•×™×§ ×‘××™×•×—×“ ×‘×¦×™×˜×•×˜×™ ×¤×¡×•×§×™× ××”×ª× "×š
- ×”×§×¤×“ ×¢×œ ×“×™×•×§ ×‘×¦×™×˜×•×˜×™× ××—×–"×œ, ×’××¨×, ××©× ×” ×•×”×œ×›×”
- ×¡××Ÿ ×¦×™×˜×•×˜×™× ×‘××™×¨×›××•×ª ×•×ª×§×Ÿ ×©×’×™××•×ª ×§×œ×•×ª ×‘×¦×™×˜×•×˜ ×× ×™×©× ×Ÿ
- ×”×ª×™×™×—×¡ ×œ×”×§×©×¨ ×”×ª×•×›×Ÿ ×›×“×™ ×œ×”×‘×™×Ÿ × ×›×•×Ÿ ×¦×™×˜×•×˜×™× ×—×œ×§×™×™× ××• ××¨×•××–×™×

### ×”×‘×—× ×” ×‘×™×Ÿ ×“×•×‘×¨×™×
- ×”×‘×—×Ÿ ×‘×‘×™×¨×•×¨ ×‘×™×Ÿ ×“×‘×¨×™ ×”×¨×‘ ×œ×©××œ×•×ª ×”×§×”×œ
- ×¡××Ÿ ×©××œ×•×ª ××”×§×”×œ ×‘×¤×•×¨××˜: [×©××œ×” ××”×§×”×œ]: ×ª×•×›×Ÿ ×”×©××œ×”
- ×¡××Ÿ ××ª ×ª×©×•×‘×ª ×”×¨×‘ ×‘×¤×•×¨××˜: [×”×¨×‘]: ×ª×•×›×Ÿ ×”×ª×©×•×‘×”
- ×× ×™×© ×“×•-×©×™×— ××¨×•×š, ×”××©×š ×œ×¡××Ÿ ×›×œ ×—×™×œ×•×¤×™ ×“×‘×¨×™×

### ×ª×™×§×•× ×™× ×—×›××™×
- ×”×¡×¨ ×—×–×¨×•×ª ××™×•×ª×¨×•×ª ×•××™×œ×•×ª ××™×œ×•×™ ××š ×©××•×¨ ×¢×œ ×“×™×•×§ ×‘×ª×•×›×Ÿ
- ×ª×§×Ÿ ×©×’×™××•×ª ×“×™×‘×•×¨ ×¨×§ ×›××©×¨ ×‘×¨×•×¨ ××”×”×§×©×¨ ××” ×”×›×•×•× ×” ×”×××™×ª×™×ª
- ×©××•×¨ ×¢×œ ×”××©××¢×•×ª ×”××“×•×™×§×ª ×’× ×›×©××ª×” ×× ×¡×— ××—×“×© ××©×¤×˜×™× ×œ× ×‘×¨×•×¨×™×
- ×‘×”×ª×œ×‘×˜×•×ª ×‘×™×Ÿ ×©×ª×™ ××¤×©×¨×•×™×•×ª ×¤×™×¨×•×©, ×‘×—×¨ ××ª ×–×• ×”××ª××™××” ×™×•×ª×¨ ×œ×”×§×©×¨ ×”×ª×•×›×Ÿ

## ××” ×œ× ×œ×¢×©×•×ª
- ××œ ×ª× ×—×© ×©××•×ª ××• ××•× ×—×™× ×›×©××ª×” ×œ× ×‘×˜×•×—, ×‘××§×•× ×–××ª ×”×©×ª××© ×‘×”×§×©×¨ ×œ×”×‘× ×” ×˜×•×‘×” ×™×•×ª×¨
- ××œ ×ª×•×¡×™×£ ×¤×¨×©× ×•×ª ××• ×”×¡×‘×¨×™× ××©×œ×š
- ××œ ×ª×©× ×” ××ª ×¡×’× ×•×Ÿ ×”×“×™×‘×•×¨ ×©×œ ×”×¨×‘
- ××œ ×ª×©××™×˜ ×“×•×’×××•×ª, ××•× ×—×™× ××§×¦×•×¢×™×™× ××• ×¦×™×˜×•×˜×™× ××•×¨×›×‘×™× ×’× ×× ×”× ×§×©×™× ×œ×”×‘× ×”

## ×¤×•×¨××˜ ×”×¤×œ×˜ ×”×¡×•×¤×™
×”×’×© ××ª ×”×ª××œ×•×œ ×›×˜×§×¡×˜ ×¨×¦×™×£ ×¢× ×—×œ×•×§×” ×˜×‘×¢×™×ª ×œ×¤×¡×§××•×ª. ×”×©×ª××© ×‘×¨×•×•×—×™× ×‘×™×Ÿ × ×•×©××™× ×©×•× ×™× ×•×©××•×¨ ×¢×œ ×¡×“×¨ ×”×’×™×•× ×™ ×©×œ ×”×¨×¢×™×•× ×•×ª.

× × ×œ×ª××œ×œ ××ª ×”×”×§×œ×˜×” ×”××¦×•×¨×¤×ª ×‘××•×¤×Ÿ ××“×•×™×§ ×œ×¤×™ ×”×”× ×—×™×•×ª ×œ×¢×™×œ."""
    else:
        # ×©×™××•×© ×‘×¤×¨×•××¤×˜ ××•×ª×× ××™×©×™×ª
        base_transcription_prompt = custom_prompt
    
    processed_transcriptions = []
    
    for i, segment_file in enumerate(segments):
        status_text.info(f"\n××¢×‘×“ ××§×˜×¢ {i+1}/{len(segments)}")
        
        # ×©×œ×‘ 1: ×ª××œ×•×œ ×™×©×™×¨×•×ª ×¢× Gemini
        raw_file = os.path.join(temp_dir, f"raw_{i:03d}.txt")
        
        # ×‘×“×™×§×” ×× ×ª××œ×•×œ ×’×•×œ××™ ×›×‘×¨ ×§×™×™× (×œ×”××©×š ×¢×™×‘×•×“ ×©×”×•×¤×¡×§)
        if os.path.exists(raw_file):
            with open(raw_file, "r", encoding="utf-8") as f:
                raw_text = f.read()
            status_text.info(f"  ××©×ª××© ×‘×ª××œ×•×œ ×’×•×œ××™ ×§×™×™×: {len(raw_text)} ×ª×•×•×™×")
        else:
            # ××¦×™××ª ×¤×¨×•×™×§×˜ ×–××™×Ÿ ×œ×ª××œ×•×œ
            project_id = token_manager.get_available_project(project_ids)
            if not project_id:
                status_text.error("×œ× × ××¦××• ×¤×¨×•×™×§×˜×™× ×¢× ××›×¡×ª ×˜×•×§× ×™× ×–××™× ×”. × ×¡×” ×©×•×‘ ××—×¨.")
                return None
            
            try:
                status_text.info(f"  ××©×ª××© ×‘×¤×¨×•×™×§×˜ {project_id} ×œ×ª××œ×•×œ")
                
                # ×˜×¢×™× ×ª ×§×•×‘×¥ ××•×“×™×•
                with open(segment_file, "rb") as audio_file:
                    audio_content = audio_file.read()
                
                # ×‘×“×™×§×ª ×’×•×“×œ ×§×•×‘×¥
                file_size = len(audio_content)
                status_text.info(f"  ×’×•×“×œ ×§×•×‘×¥ ××•×“×™×•: {file_size / 1024 / 1024:.2f} MB")
                
                # ×”×ª×××ª ×”×¤×¨×•××¤×˜ ×œ××§×˜×¢ ×¡×¤×¦×™×¤×™
                segment_prompt = base_transcription_prompt
                if i == 0:
                    segment_prompt += "\n\n×–×”×• ×”×—×œ×§ ×”×¨××©×•×Ÿ ×©×œ ×”×”×§×œ×˜×”."
                elif i == len(segments) - 1:
                    segment_prompt += f"\n\n×–×”×• ×”×—×œ×§ ×”××—×¨×•×Ÿ ×©×œ ×”×”×§×œ×˜×” (×—×œ×§ {i+1} ××ª×•×š {len(segments)})."
                else:
                    segment_prompt += f"\n\n×–×”×• ×—×œ×§ ×××¦×¢×™ ×©×œ ×”×”×§×œ×˜×” (×—×œ×§ {i+1} ××ª×•×š {len(segments)})."
                
                # ×¢×“×›×•×Ÿ ××“ ×”×ª×§×“××•×ª
                segment_progress_base = 1/3  # ×”×—×œ×§ ×”×¨××©×•×Ÿ ×©×œ ×”×ª×”×œ×™×š (×—×œ×•×§×”) ×”×•×©×œ×
                segment_progress = segment_progress_base + (i / len(segments)) / 3  # ×©×œ×™×© ×©× ×™ ×©×œ ×”×ª×”×œ×™×š
                progress_bar.progress(segment_progress, text=f"××ª××œ×œ ××§×˜×¢ {i+1}/{len(segments)}...")
                
                # ×§×¨×™××” ×œ-API ×©×œ Gemini ×¢× ×§×•×‘×¥ ×”××•×“×™×• ×›× ×¡×¤×—
                raw_text = transcribe_with_gemini(api_key, model, segment_prompt, audio_content, progress_bar)
                
                # ××•××“×Ÿ ×˜×•×§× ×™× ×¢×œ ×¡××š ××©×š ×”××•×“×™×• (××•××“×Ÿ ×’×¡)
                segment_duration_seconds = len(AudioSegment.from_mp3(segment_file)) / 1000
                estimated_tokens = int(segment_duration_seconds * 5)  # ××•××“×Ÿ ×’×¡: 5 ×˜×•×§× ×™× ×œ×©× ×™×™×”
                
                # ×¨×™×©×•× ×©×™××•×© ×‘×˜×•×§× ×™×
                token_manager.record_usage(project_id, estimated_tokens)
                
                # ×©××™×¨×ª ×”×ª××œ×•×œ ×”×’×•×œ××™
                with open(raw_file, "w", encoding="utf-8") as f:
                    f.write(raw_text)
                
                status_text.info(f"  ×ª××œ×•×œ ×”×•×©×œ×: {len(raw_text)} ×ª×•×•×™×")
            except Exception as e:
                error_msg = f"×©×’×™××” ×‘×ª××œ×•×œ ××§×˜×¢ {i+1}: {str(e)}"
                status_text.error(f"  {error_msg}")
                raw_text = f"[×©×’×™××”: {error_msg}]"
                
                # ×©××™×¨×ª ×”×•×“×¢×ª ×©×’×™××”
                with open(raw_file, "w", encoding="utf-8") as f:
                    f.write(raw_text)
        
        # ×©×œ×‘ 2: ×¢×™×‘×•×“ ×¢× Generative AI ×©×œ Gemini
        proc_file = os.path.join(temp_dir, f"processed_{i:03d}.txt")
        
        # ×‘×“×™×§×” ×× ×ª××œ×•×œ ××¢×•×‘×“ ×›×‘×¨ ×§×™×™×
        if os.path.exists(proc_file):
            with open(proc_file, "r", encoding="utf-8") as f:
                processed_text = f.read()
            status_text.info(f"  ××©×ª××© ×‘×ª××œ×•×œ ××¢×•×‘×“ ×§×™×™×: {len(processed_text)} ×ª×•×•×™×")
        else:
            # ××¦×™××ª ×¤×¨×•×™×§×˜ ×–××™×Ÿ ×œ×™×¦×™×¨×ª ×˜×§×¡×˜
            project_id = token_manager.get_available_project(project_ids)
            if not project_id:
                status_text.error("×œ× × ××¦××• ×¤×¨×•×™×§×˜×™× ×¢× ××›×¡×ª ×˜×•×§× ×™× ×–××™× ×”. × ×¡×” ×©×•×‘ ××—×¨.")
                return None
            
            try:
                status_text.info(f"  ××©×ª××© ×‘×¤×¨×•×™×§×˜ {project_id} ×œ×¢×™×‘×•×“ ×˜×§×¡×˜ ×¢× ××•×“×œ: {model}")
                
                # ×™×¦×™×¨×ª ×”×•×“×¢×ª ××¢×¨×›×ª ×¡×¤×¦×™×¤×™×ª ×œ××§×˜×¢ - ×¤×©×•×˜ ×™×•×ª×¨ ×›×¢×ª ×œ×œ× ××‘× ×” ×¤×•×¨××œ×™
                if i == 0:
                    # ××§×˜×¢ ×¨××©×•×Ÿ
                    system_message = (
                        f"{base_transcription_prompt}\n\n"
                        f"×–×”×• ×”×—×œ×§ ×”×¨××©×•×Ÿ ×©×œ ×”×©×™×¢×•×¨. ×¢×‘×“ ××ª ×”×˜×§×¡×˜ ×”×’×•×œ××™ ×œ×ª××œ×•×œ × ×§×™ ×•××“×•×™×§."
                    )
                elif i == len(segments) - 1:
                    # ××§×˜×¢ ××—×¨×•×Ÿ
                    system_message = (
                        f"{base_transcription_prompt}\n\n"
                        f"×–×”×• ×”×—×œ×§ ×”××—×¨×•×Ÿ ×©×œ ×”×©×™×¢×•×¨ (×—×œ×§ {i+1} ××ª×•×š {len(segments)}). "
                        f"×¢×‘×“ ××ª ×”×˜×§×¡×˜ ×”×’×•×œ××™ ×œ×ª××œ×•×œ × ×§×™ ×•××“×•×™×§."
                    )
                else:
                    # ××§×˜×¢ ×××¦×¢×™
                    system_message = (
                        f"{base_transcription_prompt}\n\n"
                        f"×–×”×• ×—×œ×§ ×××¦×¢×™ ×©×œ ×”×©×™×¢×•×¨ (×—×œ×§ {i+1} ××ª×•×š {len(segments)}). "
                        f"×¢×‘×“ ××ª ×”×˜×§×¡×˜ ×”×’×•×œ××™ ×œ×ª××œ×•×œ × ×§×™ ×•××“×•×™×§."
                    )
                
                # ×”×›× ×ª ×”×¤×¨×•××¤×˜
                prompt = f"{system_message}\n\n×˜×§×¡×˜ ×’×•×œ××™ ×œ×¢×™×‘×•×“:\n{raw_text}"
                
                # ××•××“×Ÿ ×¡×¤×™×¨×ª ×˜×•×§× ×™× (××•××“×Ÿ ×’×¡: 1.5 ×˜×•×§× ×™× ×œ×ª×•)
                estimated_input_tokens = int(len(prompt) * 1.5)
                estimated_output_tokens = int(len(raw_text) * 2)  # ×¤×œ×˜ ×¢×©×•×™ ×œ×”×™×•×ª ×’×“×•×œ ×™×•×ª×¨ ×‘×’×œ×œ ×¤×•×¨××˜
                estimated_total_tokens = estimated_input_tokens + estimated_output_tokens
                
                # ×¢×“×›×•×Ÿ ××“ ×”×ª×§×“××•×ª
                processing_progress_base = 2/3  # ×©× ×™ ×—×œ×§×™× ×¨××©×•× ×™× ×©×œ ×”×ª×”×œ×™×š (×—×œ×•×§×” ×•×ª××œ×•×œ) ×”×•×©×œ××•
                processing_progress = processing_progress_base + (i / len(segments)) / 3  # ×©×œ×™×© ××—×¨×•×Ÿ ×©×œ ×”×ª×”×œ×™×š
                progress_bar.progress(processing_progress, text=f"××¢×‘×“ ×ª××œ×•×œ ××§×˜×¢ {i+1}/{len(segments)}...")
                
                # ×§×¨×™××” ×™×©×™×¨×” ×œ-API ×©×œ Gemini
                gemini_url = f"https://generativelanguage.googleapis.com/v1beta/models/{model}:generateContent?key={api_key}"
                
                payload = {
                    "contents": [{"parts": [{"text": prompt}]}],
                    "generationConfig": {
                        "temperature": 0.3,
                        "maxOutputTokens": 8192
                    }
                }
                
                response = requests.post(gemini_url, json=payload)
                
                if response.status_code != 200:
                    raise Exception(f"×‘×§×©×ª API × ×›×©×œ×” ×¢× ×§×•×“ {response.status_code}: {response.text}")
                
                response_data = response.json()
                processed_text = response_data["candidates"][0]["content"]["parts"][0]["text"]
                
                # ×¨×™×©×•× ×©×™××•×© ×‘×˜×•×§× ×™×
                token_manager.record_usage(project_id, estimated_total_tokens)
                
                # ×©××™×¨×ª ×˜×§×¡×˜ ××¢×•×‘×“
                with open(proc_file, "w", encoding="utf-8") as f:
                    f.write(processed_text)
                
                status_text.info(f"  ×¢×™×‘×•×“ ×”×•×©×œ×: {len(processed_text)} ×ª×•×•×™×")
                
            except Exception as e:
                error_msg = f"×©×’×™××” ×‘×¢×™×‘×•×“ ××§×˜×¢ {i+1} ×¢× LLM: {str(e)}"
                status_text.error(f"  {error_msg}")
                processed_text = f"[×©×’×™××”: {error_msg}]\n\n{raw_text}"
                
                # ×©××™×¨×ª ×”×•×“×¢×ª ×©×’×™××” ×•×˜×§×¡×˜ ×’×•×œ××™ ×›×—×œ×•×¤×”
                with open(proc_file, "w", encoding="utf-8") as f:
                    f.write(processed_text)
        
        processed_transcriptions.append(processed_text)
        
        # ×”×©×”×™×” ×œ×× ×™×¢×ª ××’×‘×œ×•×ª ×§×¦×‘
        if i < len(segments) - 1:
            status_text.info("  ×”×©×”×™×” ×œ×× ×™×¢×ª ××’×‘×œ×•×ª ×§×¦×‘...")
            time.sleep(2)
    
    return processed_transcriptions


def combine_transcriptions(processed_transcriptions, progress_bar, status_text):
    """×©×™×œ×•×‘ ×ª××œ×•×œ×™× ××¢×•×‘×“×™× ×œ××¡××š ××—×“ ×§×•×”×¨× ×˜×™."""
    status_text.info("\n××©×œ×‘ ×ª××œ×•×œ×™×...")
    progress_bar.progress(0.95, text="××©×œ×‘ ××ª ×›×œ ×”××§×˜×¢×™×...")
    
    if not processed_transcriptions:
        status_text.error("××™×Ÿ ×ª××œ×•×œ×™× ×–××™× ×™× ×œ×©×™×œ×•×‘")
        return None
    
    # ×¢×‘×•×¨ ××§×˜×¢ ×™×—×™×“, ×¤×©×•×˜ ×œ×”×©×ª××© ×‘×• ×™×©×™×¨×•×ª
    if len(processed_transcriptions) == 1:
        combined_text = processed_transcriptions[0]
    else:
        # ××§×˜×¢ ×¨××©×•×Ÿ ×›× ×§×•×“×ª ×”×ª×—×œ×”
        combined_text = processed_transcriptions[0]
        
        # ×¢×™×‘×•×“ ××§×˜×¢×™× × ×•×¡×¤×™× - ×’×™×©×” ×¤×©×•×˜×” ×™×•×ª×¨ ×œ×œ× ×–×™×”×•×™ ××§×˜×¢×™×
        for i, segment in enumerate(processed_transcriptions[1:], 1):
            status_text.info(f"  ××©×œ×‘ ××§×˜×¢ {i+1}/{len(processed_transcriptions)}...")
            
            # × ×™×§×•×™ ×©×•×¨×•×ª ×—×•×–×¨×•×ª ×‘×ª×—×™×œ×” ×©×¢×©×•×™×•×ª ×œ×—×¤×•×£ ×¢× ×”××§×˜×¢ ×”×§×•×“×
            segment_text = segment.strip()
            
            # ×”×•×¡×¤×ª ××¢×‘×¨ ×¤×¡×§×” ×× ×¦×¨×™×š
            if not combined_text.endswith('\n\n'):
                combined_text += '\n\n'
                
            # ×¤×©×•×˜ ×”×•×¡×¤×ª ×”××§×˜×¢
            combined_text += segment_text
    
    status_text.info(f"  ××•×¨×š ×›×•×œ×œ: {len(combined_text)} ×ª×•×•×™×")
    return combined_text


def run_transcription_app():
    """×”×¤×•× ×§×¦×™×” ×”×¨××©×™×ª ×œ×”×¤×¢×œ×ª ×”××¤×œ×™×§×¦×™×”"""
    
    # ×¡×¨×’×œ ×¦×“ ×¢× ×”×’×“×¨×•×ª
    st.sidebar.header("×”×’×“×¨×•×ª ×ª××œ×•×œ")
    
    # ×”×’×“×¨×•×ª API
    api_key = st.sidebar.text_input("××¤×ª×— API ×©×œ Google AI Studio", type="password")
    projects = st.sidebar.text_input("××–×”×™ ×¤×¨×•×™×§×˜×™× ×©×œ Google Cloud (××•×¤×¨×“×™× ×‘×¤×¡×™×§×™×)", 
                                     value="project-1,project-2")
    model = st.sidebar.selectbox("××•×“×œ Google AI", 
                                ["gemini-2.0-flash", "gemini-1.5-flash", "gemini-1.5-pro"], 
                                index=0)
    
    # ×”×’×“×¨×•×ª ××§×˜×¢×™×
    with st.sidebar.expander("×”×’×“×¨×•×ª ××ª×§×“××•×ª"):
        segment_length = st.number_input("××•×¨×š ××§×˜×¢ ××§×¡×™××œ×™ (×“×§×•×ª)", 
                                        min_value=1, max_value=60, value=25)
        overlap = st.number_input("×—×¤×™×¤×” ×‘×™×Ÿ ××§×˜×¢×™× (×©× ×™×•×ª)", 
                                 min_value=0, max_value=300, value=30)
    
    # ××™×“×¢ ×¢×œ ×©×™××•×©
    st.sidebar.markdown("---")
    st.sidebar.markdown("""
    ### ×›×™×¦×“ ×œ×”×©×ª××©
    1. ×”×–×Ÿ ××¤×ª×— API ×©×œ Google AI Studio
    2. ×”×–×Ÿ ××–×”×™ ×¤×¨×•×™×§×˜×™× (×œ× ×™×”×•×œ ××›×¡×•×ª ×˜×•×§× ×™×)
    3. ×”×¢×œ×” ×§×•×‘×¥ MP3
    4. ×”×ª×× ××ª ×”×¤×¨×•××¤×˜ ×œ×¤×™ ×”×¦×•×¨×š
    5. ×œ×—×¥ ×¢×œ "×ª××œ×œ" ×•×”××ª×Ÿ ×œ×¡×™×•× ×”×ª×”×œ×™×š
    6. ×”×•×¨×“ ××ª ×”×ª××œ×•×œ ×”××œ× ×‘×¡×™×•×
    """)
    
    # Expander ×œ×¤×¨×•××¤×˜ ××•×ª×× ××™×©×™×ª
    with st.expander("×¤×¨×•××¤×˜ ××•×ª×× ××™×©×™×ª ×œ×ª××œ×•×œ", expanded=False):
        st.markdown("""
        ×›××Ÿ ×ª×•×›×œ ×œ×”×ª××™× ××ª ×”×”×•×¨××•×ª ×©×™×™×©×œ×—×• ×œ××•×“×œ ×”-AI ×œ×ª××œ×•×œ. 
        × ×™×ª×Ÿ ×œ×”×©××™×¨ ×¨×™×§ ×›×“×™ ×œ×”×©×ª××© ×‘×¤×¨×•××¤×˜ ×‘×¨×™×¨×ª ×”××—×“×œ ×©××•×ª×× ×œ×ª××œ×•×œ ×©×™×¢×•×¨×™ ×ª×•×¨×”.
        """)
        
        default_prompt = """# ×ª×¤×§×™×“×š ×”×•× ×ª××œ×•×œ ××§×¦×•×¢×™ ×©×œ ×©×™×¢×•×¨×™ ×ª×•×¨×” ×¢× ×“×’×© ×¢×œ ×“×™×•×§ ×‘×¤×¨×˜×™×
## ××˜×¨×”
××ª×” ××ª××œ×œ ××§×¦×•×¢×™ ×”××ª××—×” ×‘×ª××œ×•×œ ×©×™×¢×•×¨×™ ×ª×•×¨×” ×‘×¢×‘×¨×™×ª. ×¢×œ×™×š ×œ×™×™×¦×¨ ×˜×§×¡×˜ ××“×•×™×§ ×‘××™×•×—×“ ×ª×•×š ×©×™××•×© ×‘×”×§×©×¨ ×œ×”×‘× ×” × ×›×•× ×” ×©×œ ××™×œ×™×, ×©××•×ª ×•××•× ×—×™×.

## ×”× ×—×™×•×ª ×œ×“×™×•×§ ××‘×•×¡×¡ ×”×§×©×¨
### ×©××•×ª ×•××•×©×’×™×
- ×”×§×“×© ×ª×©×•××ª ×œ×‘ ××™×•×—×“×ª ×œ×©××•×ª ×©×œ ×¨×‘× ×™×, ×¤×¨×©× ×™×, ×¡×¤×¨×™×, ×•×—×›××™ ×ª×•×¨×”
- ×”×©×ª××© ×‘×”×§×©×¨ ×”×©×™×¢×•×¨ ×›×“×™ ×œ×–×”×•×ª × ×›×•×Ÿ ×©××•×ª ×•××•× ×—×™× ×©× ×©××¢×™× ×œ× ×‘×¨×•×¨×™×
- ×›×©××ª×” × ×ª×§×œ ×‘××™×œ×™× ×œ× ×‘×¨×•×¨×•×ª, ×”×ª×™×™×—×¡ ×œ×”×§×©×¨ ×”××©×¤×˜, × ×•×©× ×”×©×™×—×”, ×•×”×˜×¨××™× ×•×œ×•×’×™×” ×”××ª××™××”
- ×”×™×” ×–×”×™×¨ ×‘××™×•×—×“ ×¢× ××™×œ×™× ×”×•××•×¤×•× ×™×•×ª ×‘×¢×‘×¨×™×ª (××™×œ×™× ×©× ×©××¢×•×ª ×“×•××”) ×•×‘×—×¨ ××ª ×”××©××¢×•×ª ×”× ×›×•× ×” ×¢×œ ×¤×™ ×”×”×§×©×¨
- ×¢×‘×•×¨ ××•× ×—×™× ××§×¦×•×¢×™×™× (××•× ×—×™ ×”×œ×›×”, ××•×©×’×™ ×™×©×™×‘×” ×•×›×•'), ×”×©×ª××© ×‘×™×“×¢ ×©×œ×š ×›×“×™ ×œ×–×”×•×ª ××•×ª× ×‘××“×•×™×§

### ×“×™×•×§ ×‘×¦×™×˜×•×˜×™× ××”××§×•×¨×•×ª
- ×”×™×” ××“×•×™×§ ×‘××™×•×—×“ ×‘×¦×™×˜×•×˜×™ ×¤×¡×•×§×™× ××”×ª× "×š
- ×”×§×¤×“ ×¢×œ ×“×™×•×§ ×‘×¦×™×˜×•×˜×™× ××—×–"×œ, ×’××¨×, ××©× ×” ×•×”×œ×›×”
- ×¡××Ÿ ×¦×™×˜×•×˜×™× ×‘××™×¨×›××•×ª ×•×ª×§×Ÿ ×©×’×™××•×ª ×§×œ×•×ª ×‘×¦×™×˜×•×˜ ×× ×™×©× ×Ÿ

### ×”×‘×—× ×” ×‘×™×Ÿ ×“×•×‘×¨×™×
- ×”×‘×—×Ÿ ×‘×‘×™×¨×•×¨ ×‘×™×Ÿ ×“×‘×¨×™ ×”×¨×‘ ×œ×©××œ×•×ª ×”×§×”×œ
- ×¡××Ÿ ×©××œ×•×ª ××”×§×”×œ ×‘×¤×•×¨××˜: [×©××œ×” ××”×§×”×œ]: ×ª×•×›×Ÿ ×”×©××œ×”
- ×¡××Ÿ ××ª ×ª×©×•×‘×ª ×”×¨×‘ ×‘×¤×•×¨××˜: [×”×¨×‘]: ×ª×•×›×Ÿ ×”×ª×©×•×‘×”

## ××” ×œ× ×œ×¢×©×•×ª
- ××œ ×ª× ×—×© ×©××•×ª ××• ××•× ×—×™× ×›×©××ª×” ×œ× ×‘×˜×•×—, ×‘××§×•× ×–××ª ×”×©×ª××© ×‘×”×§×©×¨ ×œ×”×‘× ×” ×˜×•×‘×” ×™×•×ª×¨
- ××œ ×ª×•×¡×™×£ ×¤×¨×©× ×•×ª ××• ×”×¡×‘×¨×™× ××©×œ×š
- ××œ ×ª×©× ×” ××ª ×¡×’× ×•×Ÿ ×”×“×™×‘×•×¨ ×©×œ ×”×¨×‘
"""
        
        custom_prompt = st.text_area("×”×›× ×¡ ×¤×¨×•××¤×˜ ××•×ª×× ××™×©×™×ª", 
                                    value=default_prompt, 
                                    height=300)
    
    # ××–×•×¨ ×”×¢×œ××ª ×§×•×‘×¥
    st.markdown("## ×”×¢×œ××ª ×§×•×‘×¥ ××•×“×™×•")
    uploaded_file = st.file_uploader("×‘×—×¨ ×§×•×‘×¥ MP3 ×œ×ª××œ×•×œ", type=["mp3"])
    
    if uploaded_file is not None:
        st.audio(uploaded_file, format="audio/mp3")
        
        # ×›×¤×ª×•×¨ ×ª××œ×•×œ
        if st.button("×ª××œ×œ", type="primary"):
            if not api_key:
                st.error("× × ×œ×”×–×™×Ÿ ××¤×ª×— API ×©×œ Google AI Studio")
            elif not projects:
                st.error("× × ×œ×”×–×™×Ÿ ×œ×¤×—×•×ª ××–×”×” ×¤×¨×•×™×§×˜ ××—×“")
            else:
                # ×™×¦×™×¨×ª ××–×•×¨×™× ×œ×”×¦×’×ª ×”×ª×§×“××•×ª
                status_container = st.container()
                progress_bar = st.progress(0, text="××ª×—×™×œ...")
                
                with status_container:
                    status_text = st.empty()
                
                # ×”×¤×¢×œ×ª ×”×ª××œ×•×œ ×‘×ª×”×œ×™×š × ×¤×¨×“
                result = process_audio(
                    uploaded_file, api_key, projects, model,
                    segment_length, overlap, custom_prompt,
                    progress_bar, status_text
                )
                
                if result:
                    st.markdown("## ×ª×•×¦××•×ª ×”×ª××œ×•×œ")
                    st.text_area("×ª××œ×•×œ ××œ×", value=result, height=500)
                    
                    # ×”×•×¨×“×ª ×§×•×‘×¥
                    st.download_button(
                        label="×”×•×¨×“ ×›×§×•×‘×¥ ×˜×§×¡×˜",
                        data=result,
                        file_name=f"{uploaded_file.name.split('.')[0]}_transcription.txt",
                        mime="text/plain"
                    )

if __name__ == "__main__":
    run_transcription_app()